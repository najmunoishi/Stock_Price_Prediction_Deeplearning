{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxqoDrOPuvJy"
      },
      "source": [
        "### Stock Market Prediction And Forecasting Using Stacked LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_xaURv3FuvJ_"
      },
      "outputs": [],
      "source": [
        "### Keras and Tensorflow >2.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "2yy2nQEHuvKC"
      },
      "outputs": [],
      "source": [
        "### Data Collection\n",
        "import pandas_datareader as pdr\n",
        "key=\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lxsZ0iPcuvKH"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ygW7iEAuuvKJ"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('/content/newsp.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Af1ZX1OpuvKL",
        "outputId": "040b8482-d62b-4cda-f567-46ff4f12644c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       date   open   high    low  close    volume Name\n",
              "0  04-05-22  15.07  15.12  14.63  14.75   8407500  AAL\n",
              "1  03-05-22  14.89  15.01  14.26  14.46   8882000  AAL\n",
              "2  02-05-22  14.45  14.51  14.10  14.27   8126000  AAL\n",
              "3  01-05-22  14.30  14.94  14.25  14.66  10259500  AAL\n",
              "4  30-04-22  14.94  14.96  13.16  13.99  31879900  AAL"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72c0034a-67f3-46a2-b21e-cfb05ae2445b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>04-05-22</td>\n",
              "      <td>15.07</td>\n",
              "      <td>15.12</td>\n",
              "      <td>14.63</td>\n",
              "      <td>14.75</td>\n",
              "      <td>8407500</td>\n",
              "      <td>AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>03-05-22</td>\n",
              "      <td>14.89</td>\n",
              "      <td>15.01</td>\n",
              "      <td>14.26</td>\n",
              "      <td>14.46</td>\n",
              "      <td>8882000</td>\n",
              "      <td>AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>02-05-22</td>\n",
              "      <td>14.45</td>\n",
              "      <td>14.51</td>\n",
              "      <td>14.10</td>\n",
              "      <td>14.27</td>\n",
              "      <td>8126000</td>\n",
              "      <td>AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>01-05-22</td>\n",
              "      <td>14.30</td>\n",
              "      <td>14.94</td>\n",
              "      <td>14.25</td>\n",
              "      <td>14.66</td>\n",
              "      <td>10259500</td>\n",
              "      <td>AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>30-04-22</td>\n",
              "      <td>14.94</td>\n",
              "      <td>14.96</td>\n",
              "      <td>13.16</td>\n",
              "      <td>13.99</td>\n",
              "      <td>31879900</td>\n",
              "      <td>AAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72c0034a-67f3-46a2-b21e-cfb05ae2445b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72c0034a-67f3-46a2-b21e-cfb05ae2445b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72c0034a-67f3-46a2-b21e-cfb05ae2445b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "X5Wrj7D1uvKO",
        "outputId": "86534d8f-7d0d-43a0-e45d-a0d85933e05c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          date   open   high    low  close   volume Name\n",
              "1253  31-01-18  53.08  54.71  53.00  54.32  5962937  AAL\n",
              "1254  01-02-18  54.00  54.64  53.59  53.88  3623078  AAL\n",
              "1255  02-02-18  53.49  53.99  52.03  52.10  5109361  AAL\n",
              "1256  05-02-18  51.99  52.39  49.75  49.76  6878284  AAL\n",
              "1257  06-02-18  49.32  51.50  48.79  51.18  6782480  AAL"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7dac085b-74b9-4cc3-a193-3bcb66540360\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>31-01-18</td>\n",
              "      <td>53.08</td>\n",
              "      <td>54.71</td>\n",
              "      <td>53.00</td>\n",
              "      <td>54.32</td>\n",
              "      <td>5962937</td>\n",
              "      <td>AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>01-02-18</td>\n",
              "      <td>54.00</td>\n",
              "      <td>54.64</td>\n",
              "      <td>53.59</td>\n",
              "      <td>53.88</td>\n",
              "      <td>3623078</td>\n",
              "      <td>AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1255</th>\n",
              "      <td>02-02-18</td>\n",
              "      <td>53.49</td>\n",
              "      <td>53.99</td>\n",
              "      <td>52.03</td>\n",
              "      <td>52.10</td>\n",
              "      <td>5109361</td>\n",
              "      <td>AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1256</th>\n",
              "      <td>05-02-18</td>\n",
              "      <td>51.99</td>\n",
              "      <td>52.39</td>\n",
              "      <td>49.75</td>\n",
              "      <td>49.76</td>\n",
              "      <td>6878284</td>\n",
              "      <td>AAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1257</th>\n",
              "      <td>06-02-18</td>\n",
              "      <td>49.32</td>\n",
              "      <td>51.50</td>\n",
              "      <td>48.79</td>\n",
              "      <td>51.18</td>\n",
              "      <td>6782480</td>\n",
              "      <td>AAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dac085b-74b9-4cc3-a193-3bcb66540360')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7dac085b-74b9-4cc3-a193-3bcb66540360 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7dac085b-74b9-4cc3-a193-3bcb66540360');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hSDK7a4cuvKR"
      },
      "outputs": [],
      "source": [
        "df1=df.reset_index()['close']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWPuTdh7uvKT",
        "outputId": "3b220ec4-7cf0-4c91-c6c8-28e58489cfb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       14.75\n",
              "1       14.46\n",
              "2       14.27\n",
              "3       14.66\n",
              "4       13.99\n",
              "        ...  \n",
              "1253    54.32\n",
              "1254    53.88\n",
              "1255    52.10\n",
              "1256    49.76\n",
              "1257    51.18\n",
              "Name: close, Length: 1258, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "g-rctFZCuvKU",
        "outputId": "f7d2f833-7432-4a23-b155-95a1e5c3b88a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f93901f3f50>]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E74L82BiuvKW"
      },
      "outputs": [],
      "source": [
        "### LSTM are sensitive to the scale of the data. so we apply MinMax scaler "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoyTlLQHuvKW"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYV-agiBuvKX",
        "outputId": "62a13280-fe9a-4dca-dd4c-fd17b9892057"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       14.75\n",
              "1       14.46\n",
              "2       14.27\n",
              "3       14.66\n",
              "4       13.99\n",
              "        ...  \n",
              "1253    54.32\n",
              "1254    53.88\n",
              "1255    52.10\n",
              "1256    49.76\n",
              "1257    51.18\n",
              "Name: close, Length: 1258, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QYfROWwuvKX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler=MinMaxScaler(feature_range=(0,1))\n",
        "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRNGT1P_uvKY",
        "outputId": "a1f4c4ad-c371-46a1-95e3-940578395bee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.03806381]\n",
            " [0.03168317]\n",
            " [0.02750275]\n",
            " ...\n",
            " [0.85984598]\n",
            " [0.80836084]\n",
            " [0.83960396]]\n"
          ]
        }
      ],
      "source": [
        "print(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWyL28BuuvKY"
      },
      "outputs": [],
      "source": [
        "##splitting dataset into train and test split\n",
        "training_size=int(len(df1)*0.65)\n",
        "test_size=len(df1)-training_size\n",
        "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1orLAhFhuvKZ",
        "outputId": "d5174db8-3077-424f-a3a2-c17cfaba1c8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(817, 441)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "training_size,test_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCDZrIxYuvKZ",
        "outputId": "eada67d4-d17a-419d-b814-81ebbeeff92a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03806381],\n",
              "       [0.03168317],\n",
              "       [0.02750275],\n",
              "       [0.03608361],\n",
              "       [0.02134213],\n",
              "       [0.03256326],\n",
              "       [0.02728273],\n",
              "       [0.00682068],\n",
              "       [0.00770077],\n",
              "       [0.01210121],\n",
              "       [0.        ],\n",
              "       [0.00528053],\n",
              "       [0.00858086],\n",
              "       [0.0090209 ],\n",
              "       [0.0129813 ],\n",
              "       [0.01936194],\n",
              "       [0.02266227],\n",
              "       [0.03410341],\n",
              "       [0.03960396],\n",
              "       [0.04180418],\n",
              "       [0.04642464],\n",
              "       [0.05456546],\n",
              "       [0.06358636],\n",
              "       [0.07106711],\n",
              "       [0.06512651],\n",
              "       [0.07194719],\n",
              "       [0.08272827],\n",
              "       [0.09262926],\n",
              "       [0.08756876],\n",
              "       [0.08448845],\n",
              "       [0.07876788],\n",
              "       [0.07678768],\n",
              "       [0.07986799],\n",
              "       [0.08690869],\n",
              "       [0.08030803],\n",
              "       [0.05984598],\n",
              "       [0.05522552],\n",
              "       [0.05874587],\n",
              "       [0.05940594],\n",
              "       [0.0620462 ],\n",
              "       [0.0589659 ],\n",
              "       [0.06072607],\n",
              "       [0.06974697],\n",
              "       [0.06864686],\n",
              "       [0.05654565],\n",
              "       [0.07370737],\n",
              "       [0.0770077 ],\n",
              "       [0.06776678],\n",
              "       [0.0660066 ],\n",
              "       [0.0550055 ],\n",
              "       [0.07216722],\n",
              "       [0.07546755],\n",
              "       [0.07040704],\n",
              "       [0.07854785],\n",
              "       [0.08338834],\n",
              "       [0.08536854],\n",
              "       [0.07876788],\n",
              "       [0.08624862],\n",
              "       [0.0880088 ],\n",
              "       [0.08756876],\n",
              "       [0.08712871],\n",
              "       [0.0950495 ],\n",
              "       [0.09592959],\n",
              "       [0.10429043],\n",
              "       [0.10341034],\n",
              "       [0.11177118],\n",
              "       [0.12739274],\n",
              "       [0.13421342],\n",
              "       [0.13179318],\n",
              "       [0.12255226],\n",
              "       [0.10847085],\n",
              "       [0.1080308 ],\n",
              "       [0.11375138],\n",
              "       [0.11419142],\n",
              "       [0.11221122],\n",
              "       [0.10583058],\n",
              "       [0.10231023],\n",
              "       [0.10011001],\n",
              "       [0.10363036],\n",
              "       [0.10187019],\n",
              "       [0.08646865],\n",
              "       [0.07964796],\n",
              "       [0.0880088 ],\n",
              "       [0.09328933],\n",
              "       [0.08580858],\n",
              "       [0.08492849],\n",
              "       [0.08778878],\n",
              "       [0.0860286 ],\n",
              "       [0.08646865],\n",
              "       [0.09240924],\n",
              "       [0.08888889],\n",
              "       [0.08162816],\n",
              "       [0.0730473 ],\n",
              "       [0.06842684],\n",
              "       [0.07568757],\n",
              "       [0.06930693],\n",
              "       [0.07238724],\n",
              "       [0.07480748],\n",
              "       [0.08316832],\n",
              "       [0.0750275 ],\n",
              "       [0.08206821],\n",
              "       [0.0840484 ],\n",
              "       [0.08624862],\n",
              "       [0.09548955],\n",
              "       [0.09130913],\n",
              "       [0.09570957],\n",
              "       [0.09988999],\n",
              "       [0.10429043],\n",
              "       [0.10847085],\n",
              "       [0.11947195],\n",
              "       [0.11881188],\n",
              "       [0.11463146],\n",
              "       [0.11287129],\n",
              "       [0.11067107],\n",
              "       [0.12057206],\n",
              "       [0.12783278],\n",
              "       [0.13355336],\n",
              "       [0.13663366],\n",
              "       [0.1359736 ],\n",
              "       [0.13927393],\n",
              "       [0.13993399],\n",
              "       [0.12981298],\n",
              "       [0.13531353],\n",
              "       [0.12981298],\n",
              "       [0.12871287],\n",
              "       [0.13113311],\n",
              "       [0.12277228],\n",
              "       [0.12761276],\n",
              "       [0.07348735],\n",
              "       [0.06930693],\n",
              "       [0.05940594],\n",
              "       [0.06578658],\n",
              "       [0.05764576],\n",
              "       [0.06116612],\n",
              "       [0.06138614],\n",
              "       [0.07150715],\n",
              "       [0.06908691],\n",
              "       [0.07018702],\n",
              "       [0.05390539],\n",
              "       [0.0510451 ],\n",
              "       [0.06468647],\n",
              "       [0.06908691],\n",
              "       [0.07414741],\n",
              "       [0.08338834],\n",
              "       [0.08734873],\n",
              "       [0.08316832],\n",
              "       [0.09790979],\n",
              "       [0.11221122],\n",
              "       [0.10341034],\n",
              "       [0.10143014],\n",
              "       [0.10671067],\n",
              "       [0.11111111],\n",
              "       [0.12541254],\n",
              "       [0.12453245],\n",
              "       [0.13091309],\n",
              "       [0.12915292],\n",
              "       [0.12849285],\n",
              "       [0.13135314],\n",
              "       [0.13553355],\n",
              "       [0.14191419],\n",
              "       [0.13333333],\n",
              "       [0.13069307],\n",
              "       [0.14675468],\n",
              "       [0.15005501],\n",
              "       [0.16413641],\n",
              "       [0.16523652],\n",
              "       [0.16215622],\n",
              "       [0.1540154 ],\n",
              "       [0.15489549],\n",
              "       [0.16457646],\n",
              "       [0.16941694],\n",
              "       [0.16633663],\n",
              "       [0.16457646],\n",
              "       [0.16721672],\n",
              "       [0.17557756],\n",
              "       [0.17865787],\n",
              "       [0.18041804],\n",
              "       [0.19647965],\n",
              "       [0.18437844],\n",
              "       [0.21232123],\n",
              "       [0.20088009],\n",
              "       [0.19779978],\n",
              "       [0.20572057],\n",
              "       [0.21034103],\n",
              "       [0.19691969],\n",
              "       [0.20726073],\n",
              "       [0.21320132],\n",
              "       [0.21254125],\n",
              "       [0.20638064],\n",
              "       [0.19933993],\n",
              "       [0.22420242],\n",
              "       [0.22552255],\n",
              "       [0.2310231 ],\n",
              "       [0.22640264],\n",
              "       [0.23410341],\n",
              "       [0.23916392],\n",
              "       [0.25038504],\n",
              "       [0.24664466],\n",
              "       [0.24290429],\n",
              "       [0.24136414],\n",
              "       [0.24752475],\n",
              "       [0.24686469],\n",
              "       [0.23740374],\n",
              "       [0.24114411],\n",
              "       [0.23014301],\n",
              "       [0.22046205],\n",
              "       [0.20616062],\n",
              "       [0.19471947],\n",
              "       [0.20528053],\n",
              "       [0.20968097],\n",
              "       [0.25478548],\n",
              "       [0.26094609],\n",
              "       [0.28536854],\n",
              "       [0.27348735],\n",
              "       [0.29064906],\n",
              "       [0.2990099 ],\n",
              "       [0.28778878],\n",
              "       [0.29064906],\n",
              "       [0.28822882],\n",
              "       [0.29284928],\n",
              "       [0.28954895],\n",
              "       [0.29108911],\n",
              "       [0.28844884],\n",
              "       [0.26226623],\n",
              "       [0.25874587],\n",
              "       [0.26908691],\n",
              "       [0.27150715],\n",
              "       [0.29746975],\n",
              "       [0.30825083],\n",
              "       [0.30550055],\n",
              "       [0.32145215],\n",
              "       [0.36083608],\n",
              "       [0.35929593],\n",
              "       [0.34389439],\n",
              "       [0.34873487],\n",
              "       [0.34807481],\n",
              "       [0.35907591],\n",
              "       [0.3740374 ],\n",
              "       [0.38811881],\n",
              "       [0.4       ],\n",
              "       [0.40330033],\n",
              "       [0.38239824],\n",
              "       [0.37755776],\n",
              "       [0.41672167],\n",
              "       [0.43916392],\n",
              "       [0.45720572],\n",
              "       [0.45170517],\n",
              "       [0.46072607],\n",
              "       [0.46270627],\n",
              "       [0.45720572],\n",
              "       [0.47612761],\n",
              "       [0.49834983],\n",
              "       [0.49636964],\n",
              "       [0.48646865],\n",
              "       [0.47678768],\n",
              "       [0.48415842],\n",
              "       [0.47062706],\n",
              "       [0.46842684],\n",
              "       [0.47458746],\n",
              "       [0.49812981],\n",
              "       [0.50935094],\n",
              "       [0.51991199],\n",
              "       [0.52761276],\n",
              "       [0.52211221],\n",
              "       [0.51793179],\n",
              "       [0.52607261],\n",
              "       [0.50781078],\n",
              "       [0.53509351],\n",
              "       [0.54653465],\n",
              "       [0.56743674],\n",
              "       [0.57205721],\n",
              "       [0.57073707],\n",
              "       [0.55137514],\n",
              "       [0.53993179],\n",
              "       [0.52189219],\n",
              "       [0.51309131],\n",
              "       [0.5430143 ],\n",
              "       [0.53531353],\n",
              "       [0.52937294],\n",
              "       [0.51793179],\n",
              "       [0.5080308 ],\n",
              "       [0.52321232],\n",
              "       [0.54741474],\n",
              "       [0.5210121 ],\n",
              "       [0.50055006],\n",
              "       [0.49218922],\n",
              "       [0.51881188],\n",
              "       [0.54829483],\n",
              "       [0.54323432],\n",
              "       [0.53509351],\n",
              "       [0.51793179],\n",
              "       [0.50077008],\n",
              "       [0.50517052],\n",
              "       [0.52541254],\n",
              "       [0.489989  ],\n",
              "       [0.45456326],\n",
              "       [0.44774477],\n",
              "       [0.45544554],\n",
              "       [0.49482948],\n",
              "       [0.49240924],\n",
              "       [0.49834983],\n",
              "       [0.50913091],\n",
              "       [0.52959296],\n",
              "       [0.53333333],\n",
              "       [0.50561056],\n",
              "       [0.48712871],\n",
              "       [0.49482948],\n",
              "       [0.48514851],\n",
              "       [0.51419142],\n",
              "       [0.51639164],\n",
              "       [0.51881188],\n",
              "       [0.52035204],\n",
              "       [0.53245325],\n",
              "       [0.55511551],\n",
              "       [0.55533553],\n",
              "       [0.58019802],\n",
              "       [0.57843784],\n",
              "       [0.56809681],\n",
              "       [0.55379538],\n",
              "       [0.56116612],\n",
              "       [0.56215622],\n",
              "       [0.55489549],\n",
              "       [0.55665567],\n",
              "       [0.56545655],\n",
              "       [0.5740374 ],\n",
              "       [0.57931793],\n",
              "       [0.58921892],\n",
              "       [0.58965897],\n",
              "       [0.59713971],\n",
              "       [0.62046205],\n",
              "       [0.62530253],\n",
              "       [0.65566557],\n",
              "       [0.64664466],\n",
              "       [0.6789879 ],\n",
              "       [0.67260726],\n",
              "       [0.67414741],\n",
              "       [0.6440044 ],\n",
              "       [0.5980198 ],\n",
              "       [0.6019802 ],\n",
              "       [0.61694169],\n",
              "       [0.63476348],\n",
              "       [0.65214521],\n",
              "       [0.66094609],\n",
              "       [0.69372937],\n",
              "       [0.68954895],\n",
              "       [0.66356436],\n",
              "       [0.67964796],\n",
              "       [0.69372937],\n",
              "       [0.68162816],\n",
              "       [0.65874587],\n",
              "       [0.67854785],\n",
              "       [0.63652365],\n",
              "       [0.62926293],\n",
              "       [0.59581958],\n",
              "       [0.59933993],\n",
              "       [0.63729373],\n",
              "       [0.65566557],\n",
              "       [0.6569857 ],\n",
              "       [0.65918592],\n",
              "       [0.6750275 ],\n",
              "       [0.67018702],\n",
              "       [0.6310209 ],\n",
              "       [0.65786359],\n",
              "       [0.64818482],\n",
              "       [0.6459846 ],\n",
              "       [0.66688669],\n",
              "       [0.64114411],\n",
              "       [0.63058306],\n",
              "       [0.6       ],\n",
              "       [0.58327833],\n",
              "       [0.58371837],\n",
              "       [0.56831683],\n",
              "       [0.58107811],\n",
              "       [0.55269527],\n",
              "       [0.53157316],\n",
              "       [0.53773377],\n",
              "       [0.52453245],\n",
              "       [0.53157316],\n",
              "       [0.5489549 ],\n",
              "       [0.53905391],\n",
              "       [0.55225523],\n",
              "       [0.58415842],\n",
              "       [0.57579758],\n",
              "       [0.60814081],\n",
              "       [0.60308031],\n",
              "       [0.60682068],\n",
              "       [0.58283828],\n",
              "       [0.59031903],\n",
              "       [0.58085809],\n",
              "       [0.57359736],\n",
              "       [0.57139714],\n",
              "       [0.57535754],\n",
              "       [0.5689989 ],\n",
              "       [0.60462046],\n",
              "       [0.57469747],\n",
              "       [0.559956  ],\n",
              "       [0.54631463],\n",
              "       [0.55467547],\n",
              "       [0.54873487],\n",
              "       [0.56237624],\n",
              "       [0.55159516],\n",
              "       [0.54191419],\n",
              "       [0.52915292],\n",
              "       [0.54917492],\n",
              "       [0.53773377],\n",
              "       [0.55071507],\n",
              "       [0.51947195],\n",
              "       [0.49636964],\n",
              "       [0.49086909],\n",
              "       [0.50825083],\n",
              "       [0.48822882],\n",
              "       [0.50407041],\n",
              "       [0.48426843],\n",
              "       [0.49416942],\n",
              "       [0.47018702],\n",
              "       [0.46006601],\n",
              "       [0.51067107],\n",
              "       [0.48206821],\n",
              "       [0.46358636],\n",
              "       [0.43960396],\n",
              "       [0.41716172],\n",
              "       [0.39075908],\n",
              "       [0.34235424],\n",
              "       [0.40682068],\n",
              "       [0.41078108],\n",
              "       [0.43894389],\n",
              "       [0.4479648 ],\n",
              "       [0.48844884],\n",
              "       [0.54631463],\n",
              "       [0.52849285],\n",
              "       [0.56017602],\n",
              "       [0.58965897],\n",
              "       [0.59163916],\n",
              "       [0.59889989],\n",
              "       [0.59229923],\n",
              "       [0.60022002],\n",
              "       [0.62332233],\n",
              "       [0.63762376],\n",
              "       [0.6530253 ],\n",
              "       [0.64312431],\n",
              "       [0.66270627],\n",
              "       [0.6640264 ],\n",
              "       [0.67788779],\n",
              "       [0.66930693],\n",
              "       [0.66908691],\n",
              "       [0.68426843],\n",
              "       [0.68184818],\n",
              "       [0.67480748],\n",
              "       [0.70473047],\n",
              "       [0.68382838],\n",
              "       [0.68514851],\n",
              "       [0.66644664],\n",
              "       [0.66424642],\n",
              "       [0.68492849],\n",
              "       [0.7029703 ],\n",
              "       [0.78129813],\n",
              "       [0.7669967 ],\n",
              "       [0.76655666],\n",
              "       [0.77491749],\n",
              "       [0.80594059],\n",
              "       [0.83586359],\n",
              "       [0.83168317],\n",
              "       [0.77645765],\n",
              "       [0.79031903],\n",
              "       [0.82530253],\n",
              "       [0.8129813 ],\n",
              "       [0.83212321],\n",
              "       [0.76875688],\n",
              "       [0.78723872],\n",
              "       [0.81672167],\n",
              "       [0.82926293],\n",
              "       [0.83212321],\n",
              "       [0.81826183],\n",
              "       [0.84510451],\n",
              "       [0.85665567],\n",
              "       [0.87634763],\n",
              "       [0.88888889],\n",
              "       [0.89350935],\n",
              "       [0.89966997],\n",
              "       [0.89889989],\n",
              "       [0.88052805],\n",
              "       [0.87986799],\n",
              "       [0.89416942],\n",
              "       [0.85808581],\n",
              "       [0.80440044],\n",
              "       [0.82244224],\n",
              "       [0.80066007],\n",
              "       [0.80066007],\n",
              "       [0.80946095],\n",
              "       [0.87414741],\n",
              "       [0.89438944],\n",
              "       [0.93663366],\n",
              "       [0.93883388],\n",
              "       [0.93355336],\n",
              "       [0.87293729],\n",
              "       [0.82728273],\n",
              "       [0.86292629],\n",
              "       [0.79339934],\n",
              "       [0.78547855],\n",
              "       [0.75863586],\n",
              "       [0.80176018],\n",
              "       [0.78745875],\n",
              "       [0.77282728],\n",
              "       [0.73729373],\n",
              "       [0.77073707],\n",
              "       [0.76061606],\n",
              "       [0.7669967 ],\n",
              "       [0.77821782],\n",
              "       [0.76985699],\n",
              "       [0.79845985],\n",
              "       [0.80880088],\n",
              "       [0.83608361],\n",
              "       [0.84246425],\n",
              "       [0.84708471],\n",
              "       [0.80770077],\n",
              "       [0.79933993],\n",
              "       [0.76743674],\n",
              "       [0.77645765],\n",
              "       [0.78657866],\n",
              "       [0.79053905],\n",
              "       [0.77832783],\n",
              "       [0.76952695],\n",
              "       [0.76787679],\n",
              "       [0.74180418],\n",
              "       [0.75621562],\n",
              "       [0.78459846],\n",
              "       [0.79647965],\n",
              "       [0.81848185],\n",
              "       [0.89482948],\n",
              "       [0.90451045],\n",
              "       [0.92783278],\n",
              "       [0.94037404],\n",
              "       [0.91034103],\n",
              "       [0.90011001],\n",
              "       [0.85786579],\n",
              "       [0.84147415],\n",
              "       [0.87216722],\n",
              "       [0.89372937],\n",
              "       [0.87480748],\n",
              "       [0.82332233],\n",
              "       [0.79548955],\n",
              "       [0.77139714],\n",
              "       [0.75852585],\n",
              "       [0.78591859],\n",
              "       [0.76611661],\n",
              "       [0.76369637],\n",
              "       [0.7650165 ],\n",
              "       [0.75687569],\n",
              "       [0.76413641],\n",
              "       [0.77491749],\n",
              "       [0.77381738],\n",
              "       [0.80836084],\n",
              "       [0.84356436],\n",
              "       [0.84444444],\n",
              "       [0.84554455],\n",
              "       [0.87315732],\n",
              "       [0.85478548],\n",
              "       [0.83982398],\n",
              "       [0.7889989 ],\n",
              "       [0.77590759],\n",
              "       [0.80022002],\n",
              "       [0.79053905],\n",
              "       [0.74774477],\n",
              "       [0.74862486],\n",
              "       [0.7929593 ],\n",
              "       [0.79251925],\n",
              "       [0.80583058],\n",
              "       [0.78833883],\n",
              "       [0.78041804],\n",
              "       [0.78756876],\n",
              "       [0.78426843],\n",
              "       [0.79163916],\n",
              "       [0.76633663],\n",
              "       [0.66094609],\n",
              "       [0.6479648 ],\n",
              "       [0.6510451 ],\n",
              "       [0.62783278],\n",
              "       [0.64290429],\n",
              "       [0.6369637 ],\n",
              "       [0.64576458],\n",
              "       [0.68558856],\n",
              "       [0.67667767],\n",
              "       [0.66248625],\n",
              "       [0.64136414],\n",
              "       [0.63146315],\n",
              "       [0.59053905],\n",
              "       [0.60077008],\n",
              "       [0.60308031],\n",
              "       [0.59405941],\n",
              "       [0.60913091],\n",
              "       [0.59515952],\n",
              "       [0.58217822],\n",
              "       [0.5909791 ],\n",
              "       [0.59306931],\n",
              "       [0.62794279],\n",
              "       [0.66028603],\n",
              "       [0.65357536],\n",
              "       [0.64290429],\n",
              "       [0.64290429],\n",
              "       [0.62530253],\n",
              "       [0.58811881],\n",
              "       [0.59218922],\n",
              "       [0.56721672],\n",
              "       [0.57227723],\n",
              "       [0.58767877],\n",
              "       [0.60847085],\n",
              "       [0.57843784],\n",
              "       [0.58635864],\n",
              "       [0.62024202],\n",
              "       [0.64686469],\n",
              "       [0.63894389],\n",
              "       [0.62750275],\n",
              "       [0.62420242],\n",
              "       [0.62442244],\n",
              "       [0.60572057],\n",
              "       [0.61342134],\n",
              "       [0.62508251],\n",
              "       [0.6510451 ],\n",
              "       [0.58547855],\n",
              "       [0.59669967],\n",
              "       [0.61936194],\n",
              "       [0.60968097],\n",
              "       [0.59955996],\n",
              "       [0.59581958],\n",
              "       [0.63124312],\n",
              "       [0.65390539],\n",
              "       [0.65874587],\n",
              "       [0.64158416],\n",
              "       [0.62640264],\n",
              "       [0.63058306],\n",
              "       [0.6530253 ],\n",
              "       [0.64906491],\n",
              "       [0.65236524],\n",
              "       [0.6569857 ],\n",
              "       [0.68052805],\n",
              "       [0.67348735],\n",
              "       [0.67128713],\n",
              "       [0.63718372],\n",
              "       [0.58811881],\n",
              "       [0.54125413],\n",
              "       [0.53861386],\n",
              "       [0.56831683],\n",
              "       [0.57227723],\n",
              "       [0.56325633],\n",
              "       [0.57117712],\n",
              "       [0.5760176 ],\n",
              "       [0.62684268],\n",
              "       [0.61320132],\n",
              "       [0.60682068],\n",
              "       [0.61122112],\n",
              "       [0.61562156],\n",
              "       [0.62024202],\n",
              "       [0.64092409],\n",
              "       [0.6440044 ],\n",
              "       [0.65170517],\n",
              "       [0.66094609],\n",
              "       [0.68140814],\n",
              "       [0.67040704],\n",
              "       [0.66468647],\n",
              "       [0.61980198],\n",
              "       [0.62090209],\n",
              "       [0.59911991],\n",
              "       [0.59889989],\n",
              "       [0.57337734],\n",
              "       [0.57557756],\n",
              "       [0.56787679],\n",
              "       [0.5760176 ],\n",
              "       [0.56347635],\n",
              "       [0.59779978],\n",
              "       [0.55247525],\n",
              "       [0.57843784],\n",
              "       [0.58789879],\n",
              "       [0.64686469],\n",
              "       [0.67810781],\n",
              "       [0.66864686],\n",
              "       [0.67722772],\n",
              "       [0.69174917],\n",
              "       [0.67524752],\n",
              "       [0.69152915],\n",
              "       [0.6990099 ],\n",
              "       [0.68844884],\n",
              "       [0.72541254],\n",
              "       [0.71837184],\n",
              "       [0.7359736 ],\n",
              "       [0.73575358],\n",
              "       [0.72255226],\n",
              "       [0.72255226],\n",
              "       [0.73047305],\n",
              "       [0.7359736 ],\n",
              "       [0.73663366],\n",
              "       [0.71749175],\n",
              "       [0.71683168],\n",
              "       [0.71111111],\n",
              "       [0.69592959],\n",
              "       [0.69240924],\n",
              "       [0.69020902],\n",
              "       [0.67942794],\n",
              "       [0.66952695],\n",
              "       [0.65588559],\n",
              "       [0.64422442],\n",
              "       [0.63212321],\n",
              "       [0.64422442],\n",
              "       [0.6420242 ],\n",
              "       [0.64422442],\n",
              "       [0.62068207],\n",
              "       [0.62244224],\n",
              "       [0.63080308],\n",
              "       [0.62134213],\n",
              "       [0.66534653],\n",
              "       [0.67766777],\n",
              "       [0.66556656],\n",
              "       [0.7029703 ],\n",
              "       [0.72079208],\n",
              "       [0.69372937],\n",
              "       [0.67392739],\n",
              "       [0.68360836],\n",
              "       [0.63960396],\n",
              "       [0.63256326],\n",
              "       [0.65071507],\n",
              "       [0.6640264 ],\n",
              "       [0.64774477],\n",
              "       [0.61760176],\n",
              "       [0.64642464],\n",
              "       [0.65731573],\n",
              "       [0.6660066 ],\n",
              "       [0.67744774],\n",
              "       [0.66468647],\n",
              "       [0.67062706],\n",
              "       [0.65522552],\n",
              "       [0.64532453],\n",
              "       [0.61364136],\n",
              "       [0.60506051],\n",
              "       [0.62068207],\n",
              "       [0.60352035],\n",
              "       [0.60176018],\n",
              "       [0.61738174],\n",
              "       [0.63762376],\n",
              "       [0.59581958],\n",
              "       [0.60572057],\n",
              "       [0.56633663],\n",
              "       [0.56853685],\n",
              "       [0.57293729],\n",
              "       [0.5889989 ],\n",
              "       [0.59713971],\n",
              "       [0.5689769 ],\n",
              "       [0.58569857],\n",
              "       [0.58679868],\n",
              "       [0.55269527],\n",
              "       [0.57139714],\n",
              "       [0.579978  ],\n",
              "       [0.52827283],\n",
              "       [0.53883388],\n",
              "       [0.55423542],\n",
              "       [0.52211221],\n",
              "       [0.49570957],\n",
              "       [0.50979098],\n",
              "       [0.53025303],\n",
              "       [0.51639164],\n",
              "       [0.54565457],\n",
              "       [0.5630363 ],\n",
              "       [0.57909791],\n",
              "       [0.58349835],\n",
              "       [0.58833883],\n",
              "       [0.61210121],\n",
              "       [0.6019802 ],\n",
              "       [0.60814081],\n",
              "       [0.62354235],\n",
              "       [0.61276128],\n",
              "       [0.61562156],\n",
              "       [0.63388339],\n",
              "       [0.62860286],\n",
              "       [0.6349835 ],\n",
              "       [0.62948295],\n",
              "       [0.64048405],\n",
              "       [0.61056106],\n",
              "       [0.62992299],\n",
              "       [0.62948295],\n",
              "       [0.6479648 ],\n",
              "       [0.65060506],\n",
              "       [0.640044  ],\n",
              "       [0.64444444],\n",
              "       [0.63982398],\n",
              "       [0.66930693],\n",
              "       [0.669967  ],\n",
              "       [0.65434543],\n",
              "       [0.63586359],\n",
              "       [0.60462046],\n",
              "       [0.61364136],\n",
              "       [0.62332233],\n",
              "       [0.6239824 ],\n",
              "       [0.61584158],\n",
              "       [0.58305831],\n",
              "       [0.57975798],\n",
              "       [0.57007701],\n",
              "       [0.56941694],\n",
              "       [0.55753575],\n",
              "       [0.56061606],\n",
              "       [0.56567657],\n",
              "       [0.57579758],\n",
              "       [0.59229923],\n",
              "       [0.61936194],\n",
              "       [0.61364136],\n",
              "       [0.61386139],\n",
              "       [0.62310231],\n",
              "       [0.62134213],\n",
              "       [0.59383938],\n",
              "       [0.55423542],\n",
              "       [0.52761276],\n",
              "       [0.52585259],\n",
              "       [0.52123212],\n",
              "       [0.5049505 ],\n",
              "       [0.47678768],\n",
              "       [0.47106711],\n",
              "       [0.47436744],\n",
              "       [0.44422442],\n",
              "       [0.43531353],\n",
              "       [0.44026403]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwbFwraVuvKa"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "# convert an array of values into a dataset matrix\n",
        "def create_dataset(dataset, time_step=1):\n",
        "\tdataX, dataY = [], []\n",
        "\tfor i in range(len(dataset)-time_step-1):\n",
        "\t\ta = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
        "\t\tdataX.append(a)\n",
        "\t\tdataY.append(dataset[i + time_step, 0])\n",
        "\treturn numpy.array(dataX), numpy.array(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urbRWbyIuvKb"
      },
      "outputs": [],
      "source": [
        "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
        "time_step = 100\n",
        "X_train, y_train = create_dataset(train_data, time_step)\n",
        "X_test, ytest = create_dataset(test_data, time_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezM28WChuvKb",
        "outputId": "19948a8b-f944-4cda-a434-579256fb2bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(716, 100)\n",
            "(716,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "print(X_train.shape), print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHCFqTQYuvKc",
        "outputId": "69c54257-636e-441a-ffd4-f4e207205dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(340, 100)\n",
            "(340,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "print(X_test.shape), print(ytest.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1wEm8ILuvKc"
      },
      "outputs": [],
      "source": [
        "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
        "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
        "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmMvCulLuvKd"
      },
      "outputs": [],
      "source": [
        "### Create the Stacked LSTM model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YEcjHCKiuvKd"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
        "model.add(LSTM(50,return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error',optimizer='adam')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPcp4F58uvKe",
        "outputId": "1d0d44a2-e077-4892-82e4-bf6cd578c11f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100, 50)           10400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100, 50)           20200     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 50)                20200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,851\n",
            "Trainable params: 50,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JebrNOsuvKe",
        "outputId": "17c21e6c-51d9-422d-b832-b6176eb960eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100, 50)           10400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100, 50)           20200     \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 50)                20200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 50,851\n",
            "Trainable params: 50,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akJghWNxuvKf",
        "outputId": "18360e18-0e34-4b3d-adab-97ce77e1cf20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 11s 302ms/step - loss: 0.0884 - val_loss: 0.0198\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 2s 200ms/step - loss: 0.0138 - val_loss: 0.0044\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 2s 192ms/step - loss: 0.0083 - val_loss: 0.0124\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 2s 189ms/step - loss: 0.0047 - val_loss: 0.0051\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 2s 177ms/step - loss: 0.0035 - val_loss: 0.0030\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 2s 177ms/step - loss: 0.0030 - val_loss: 0.0039\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 2s 188ms/step - loss: 0.0029 - val_loss: 0.0026\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 2s 176ms/step - loss: 0.0033 - val_loss: 0.0028\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 2s 196ms/step - loss: 0.0029 - val_loss: 0.0029\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 2s 179ms/step - loss: 0.0030 - val_loss: 0.0032\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 2s 176ms/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 2s 179ms/step - loss: 0.0028 - val_loss: 0.0025\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0027 - val_loss: 0.0034\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 2s 179ms/step - loss: 0.0027 - val_loss: 0.0027\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0026 - val_loss: 0.0021\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 2s 184ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 2s 179ms/step - loss: 0.0023 - val_loss: 0.0034\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 2s 177ms/step - loss: 0.0025 - val_loss: 0.0030\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 2s 179ms/step - loss: 0.0024 - val_loss: 0.0020\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 2s 190ms/step - loss: 0.0023 - val_loss: 0.0030\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 2s 184ms/step - loss: 0.0023 - val_loss: 0.0031\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 2s 180ms/step - loss: 0.0022 - val_loss: 0.0023\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 2s 176ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0021 - val_loss: 0.0017\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 2s 179ms/step - loss: 0.0022 - val_loss: 0.0040\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 2s 190ms/step - loss: 0.0024 - val_loss: 0.0022\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 2s 184ms/step - loss: 0.0024 - val_loss: 0.0028\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 2s 183ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 2s 179ms/step - loss: 0.0021 - val_loss: 0.0023\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 2s 182ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 2s 180ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 2s 175ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 2s 179ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 3s 238ms/step - loss: 0.0020 - val_loss: 0.0022\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 2s 191ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 2s 190ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 2s 183ms/step - loss: 0.0019 - val_loss: 0.0019\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 2s 180ms/step - loss: 0.0020 - val_loss: 0.0016\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0020 - val_loss: 0.0014\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 0.0018 - val_loss: 0.0021\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 2s 187ms/step - loss: 0.0018 - val_loss: 0.0013\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 2s 177ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0017 - val_loss: 0.0015\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0019 - val_loss: 0.0023\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 2s 187ms/step - loss: 0.0017 - val_loss: 0.0012\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 2s 187ms/step - loss: 0.0019 - val_loss: 0.0014\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 2s 180ms/step - loss: 0.0016 - val_loss: 0.0012\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 2s 189ms/step - loss: 0.0016 - val_loss: 0.0011\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 2s 184ms/step - loss: 0.0015 - val_loss: 0.0011\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 2s 183ms/step - loss: 0.0014 - val_loss: 0.0010\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 2s 182ms/step - loss: 0.0014 - val_loss: 0.0017\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 2s 184ms/step - loss: 0.0014 - val_loss: 9.3062e-04\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 2s 185ms/step - loss: 0.0013 - val_loss: 9.6311e-04\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 2s 182ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0015 - val_loss: 0.0019\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0014 - val_loss: 8.7714e-04\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 2s 182ms/step - loss: 0.0013 - val_loss: 8.5433e-04\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 2s 180ms/step - loss: 0.0011 - val_loss: 8.2782e-04\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 2s 204ms/step - loss: 0.0011 - val_loss: 0.0016\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 2s 189ms/step - loss: 0.0012 - val_loss: 0.0011\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 2s 187ms/step - loss: 0.0010 - val_loss: 9.6705e-04\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 2s 194ms/step - loss: 0.0011 - val_loss: 8.5671e-04\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 2s 197ms/step - loss: 9.7733e-04 - val_loss: 7.2931e-04\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 2s 202ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 2s 190ms/step - loss: 0.0011 - val_loss: 7.2176e-04\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 2s 187ms/step - loss: 9.0824e-04 - val_loss: 0.0012\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 2s 208ms/step - loss: 8.6274e-04 - val_loss: 6.9423e-04\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 2s 185ms/step - loss: 8.8476e-04 - val_loss: 7.1229e-04\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 2s 182ms/step - loss: 9.7690e-04 - val_loss: 6.7514e-04\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 2s 183ms/step - loss: 8.2063e-04 - val_loss: 6.5738e-04\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 2s 178ms/step - loss: 8.7149e-04 - val_loss: 6.6424e-04\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 2s 179ms/step - loss: 8.6590e-04 - val_loss: 7.6243e-04\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 2s 180ms/step - loss: 8.1554e-04 - val_loss: 6.6626e-04\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 2s 186ms/step - loss: 7.5393e-04 - val_loss: 8.8532e-04\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 2s 189ms/step - loss: 8.9428e-04 - val_loss: 9.3217e-04\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 2s 200ms/step - loss: 7.7300e-04 - val_loss: 6.8404e-04\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 2s 188ms/step - loss: 8.5492e-04 - val_loss: 0.0017\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 2s 180ms/step - loss: 8.4123e-04 - val_loss: 0.0011\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 8.4761e-04 - val_loss: 6.2602e-04\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 2s 184ms/step - loss: 7.3764e-04 - val_loss: 8.8169e-04\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 2s 195ms/step - loss: 8.7005e-04 - val_loss: 8.3305e-04\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 2s 205ms/step - loss: 8.0007e-04 - val_loss: 6.0191e-04\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 2s 204ms/step - loss: 7.6094e-04 - val_loss: 6.9924e-04\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 2s 202ms/step - loss: 7.4480e-04 - val_loss: 5.7083e-04\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 2s 203ms/step - loss: 7.4036e-04 - val_loss: 6.2472e-04\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 2s 181ms/step - loss: 7.3124e-04 - val_loss: 6.2541e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f93149e7bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di-_3gs8uvKf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BRVJHAuKuvKf",
        "outputId": "1fe6d1fa-3018-4c12-9694-421b9ec7ff24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9Uifv5BuvKg"
      },
      "outputs": [],
      "source": [
        "### Lets Do the prediction and check performance metrics\n",
        "train_predict=model.predict(X_train)\n",
        "test_predict=model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fSMRTBSuvKg"
      },
      "outputs": [],
      "source": [
        "##Transformback to original form\n",
        "train_predict=scaler.inverse_transform(train_predict)\n",
        "test_predict=scaler.inverse_transform(test_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp8n6UX4uvKg",
        "outputId": "4b815bd4-192e-4c2e-ad31-8f99cefa7753"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38.4608319204746"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "### Calculate RMSE performance metrics\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "math.sqrt(mean_squared_error(y_train,train_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UActZ0NHuvKh",
        "outputId": "62aa0a2b-8dfe-4bd6-adce-2525c0f55cc6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46.1989793449326"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "### Test Data RMSE\n",
        "math.sqrt(mean_squared_error(ytest,test_predict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "kT_hqTLruvKh",
        "outputId": "8026a93e-5c51-4cda-aba1-28fe0d69a427"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "### Plotting \n",
        "# shift train predictions for plotting\n",
        "look_back=100\n",
        "trainPredictPlot = numpy.empty_like(df1)\n",
        "trainPredictPlot[:, :] = np.nan\n",
        "trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
        "# shift test predictions for plotting\n",
        "testPredictPlot = numpy.empty_like(df1)\n",
        "testPredictPlot[:, :] = numpy.nan\n",
        "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
        "# plot baseline and predictions\n",
        "plt.plot(scaler.inverse_transform(df1))\n",
        "plt.plot(trainPredictPlot)\n",
        "plt.plot(testPredictPlot)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0phoasNuvKi",
        "outputId": "acccf2e2-0888-4f9e-bd27-2372e12fe00f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "441"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "len(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toXKASSYcWTt",
        "outputId": "271005bc-91ba-46a4-a2ee-9dfc6ae071f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "817"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BO2FufKAuvKi",
        "outputId": "eb5cebb0-92eb-4b95-b920-038bee9c06bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "x_input=test_data[341:].reshape(1,-1)\n",
        "x_input.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8exn1ajruvKj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHvgDHzcuvKj"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJjdt6YMuvKj"
      },
      "outputs": [],
      "source": [
        "temp_input=list(x_input)\n",
        "temp_input=temp_input[0].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ua6FQJdluvKj",
        "outputId": "86aff9f6-064e-488a-9908-673b24b4ef8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7298129812981298,\n",
              " 0.7256325632563256,\n",
              " 0.7104510451045104,\n",
              " 0.68998899889989,\n",
              " 0.7128712871287128,\n",
              " 0.7320132013201319,\n",
              " 0.7489548954895489,\n",
              " 0.7630363036303631,\n",
              " 0.7603960396039604,\n",
              " 0.7443344334433444,\n",
              " 0.7584158415841584,\n",
              " 0.7584158415841584,\n",
              " 0.7636963696369636,\n",
              " 0.8248624862486247,\n",
              " 0.8297029702970296,\n",
              " 0.825962596259626,\n",
              " 0.8422442244224422,\n",
              " 0.8268426842684269,\n",
              " 0.8803080308030802,\n",
              " 0.8759075907590759,\n",
              " 0.8719471947194719,\n",
              " 0.873047304730473,\n",
              " 0.8635863586358636,\n",
              " 0.8591859185918591,\n",
              " 0.8583058305830582,\n",
              " 0.8468646864686467,\n",
              " 0.856105610561056,\n",
              " 0.8352035203520352,\n",
              " 0.8565456545654566,\n",
              " 0.8360836083608361,\n",
              " 0.7830583058305829,\n",
              " 0.7599559955995598,\n",
              " 0.753135313531353,\n",
              " 0.7436743674367436,\n",
              " 0.7661166116611662,\n",
              " 0.7555555555555555,\n",
              " 0.7575357535753575,\n",
              " 0.7588558855885588,\n",
              " 0.7357535753575357,\n",
              " 0.7337733773377337,\n",
              " 0.7205720572057206,\n",
              " 0.7216721672167217,\n",
              " 0.7199119911991199,\n",
              " 0.7214521452145215,\n",
              " 0.7518151815181517,\n",
              " 0.7625962596259626,\n",
              " 0.7562156215621563,\n",
              " 0.7628162816281627,\n",
              " 0.7839383938393838,\n",
              " 0.784158415841584,\n",
              " 0.781958195819582,\n",
              " 0.7788778877887788,\n",
              " 0.7964796479647964,\n",
              " 0.7971397139713972,\n",
              " 0.8244224422442243,\n",
              " 0.7916391639163916,\n",
              " 0.8121012101210121,\n",
              " 0.8019801980198018,\n",
              " 0.8050605060506051,\n",
              " 0.833003300330033,\n",
              " 0.8360836083608361,\n",
              " 0.8422442244224422,\n",
              " 0.823982398239824,\n",
              " 0.8156215621562157,\n",
              " 0.8182618261826182,\n",
              " 0.836963696369637,\n",
              " 0.8464246424642463,\n",
              " 0.8453245324532452,\n",
              " 0.8558855885588559,\n",
              " 0.875027502750275,\n",
              " 0.8706270627062707,\n",
              " 0.8763476347634762,\n",
              " 0.8664466446644663,\n",
              " 0.8677667766776678,\n",
              " 0.8583058305830582,\n",
              " 0.8794279427942795,\n",
              " 0.8651265126512651,\n",
              " 0.8723872387238722,\n",
              " 0.8719471947194719,\n",
              " 0.8605060506050606,\n",
              " 0.8594059405940593,\n",
              " 0.8968096809680968,\n",
              " 0.9548954895489548,\n",
              " 1.0,\n",
              " 0.989218921892189,\n",
              " 0.9931793179317929,\n",
              " 0.9971397139713971,\n",
              " 0.990979097909791,\n",
              " 0.9918591859185919,\n",
              " 0.996039603960396,\n",
              " 0.9190319031903189,\n",
              " 0.8807480748074805,\n",
              " 0.8811881188118811,\n",
              " 0.8726072607260726,\n",
              " 0.8706270627062707,\n",
              " 0.9086908690869087,\n",
              " 0.8990099009900989,\n",
              " 0.8598459845984598,\n",
              " 0.8083608360836083,\n",
              " 0.8396039603960395]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "temp_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u009USWZuvKk",
        "outputId": "6d2d94b3-4d9f-4ee8-b354-d9d6dfa3f199"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.83318985]\n",
            "101\n",
            "1 day input [0.72563256 0.71045105 0.689989   0.71287129 0.7320132  0.7489549\n",
            " 0.7630363  0.76039604 0.74433443 0.75841584 0.75841584 0.76369637\n",
            " 0.82486249 0.82970297 0.8259626  0.84224422 0.82684268 0.88030803\n",
            " 0.87590759 0.87194719 0.8730473  0.86358636 0.85918592 0.85830583\n",
            " 0.84686469 0.85610561 0.83520352 0.85654565 0.83608361 0.78305831\n",
            " 0.759956   0.75313531 0.74367437 0.76611661 0.75555556 0.75753575\n",
            " 0.75885589 0.73575358 0.73377338 0.72057206 0.72167217 0.71991199\n",
            " 0.72145215 0.75181518 0.76259626 0.75621562 0.76281628 0.78393839\n",
            " 0.78415842 0.7819582  0.77887789 0.79647965 0.79713971 0.82442244\n",
            " 0.79163916 0.81210121 0.8019802  0.80506051 0.8330033  0.83608361\n",
            " 0.84224422 0.8239824  0.81562156 0.81826183 0.8369637  0.84642464\n",
            " 0.84532453 0.85588559 0.8750275  0.87062706 0.87634763 0.86644664\n",
            " 0.86776678 0.85830583 0.87942794 0.86512651 0.87238724 0.87194719\n",
            " 0.86050605 0.85940594 0.89680968 0.95489549 1.         0.98921892\n",
            " 0.99317932 0.99713971 0.9909791  0.99185919 0.9960396  0.9190319\n",
            " 0.88074807 0.88118812 0.87260726 0.87062706 0.90869087 0.8990099\n",
            " 0.85984598 0.80836084 0.83960396 0.83318985]\n",
            "1 day output [[0.82914275]]\n",
            "2 day input [0.71045105 0.689989   0.71287129 0.7320132  0.7489549  0.7630363\n",
            " 0.76039604 0.74433443 0.75841584 0.75841584 0.76369637 0.82486249\n",
            " 0.82970297 0.8259626  0.84224422 0.82684268 0.88030803 0.87590759\n",
            " 0.87194719 0.8730473  0.86358636 0.85918592 0.85830583 0.84686469\n",
            " 0.85610561 0.83520352 0.85654565 0.83608361 0.78305831 0.759956\n",
            " 0.75313531 0.74367437 0.76611661 0.75555556 0.75753575 0.75885589\n",
            " 0.73575358 0.73377338 0.72057206 0.72167217 0.71991199 0.72145215\n",
            " 0.75181518 0.76259626 0.75621562 0.76281628 0.78393839 0.78415842\n",
            " 0.7819582  0.77887789 0.79647965 0.79713971 0.82442244 0.79163916\n",
            " 0.81210121 0.8019802  0.80506051 0.8330033  0.83608361 0.84224422\n",
            " 0.8239824  0.81562156 0.81826183 0.8369637  0.84642464 0.84532453\n",
            " 0.85588559 0.8750275  0.87062706 0.87634763 0.86644664 0.86776678\n",
            " 0.85830583 0.87942794 0.86512651 0.87238724 0.87194719 0.86050605\n",
            " 0.85940594 0.89680968 0.95489549 1.         0.98921892 0.99317932\n",
            " 0.99713971 0.9909791  0.99185919 0.9960396  0.9190319  0.88074807\n",
            " 0.88118812 0.87260726 0.87062706 0.90869087 0.8990099  0.85984598\n",
            " 0.80836084 0.83960396 0.83318985 0.82914275]\n",
            "2 day output [[0.83094275]]\n",
            "3 day input [0.689989   0.71287129 0.7320132  0.7489549  0.7630363  0.76039604\n",
            " 0.74433443 0.75841584 0.75841584 0.76369637 0.82486249 0.82970297\n",
            " 0.8259626  0.84224422 0.82684268 0.88030803 0.87590759 0.87194719\n",
            " 0.8730473  0.86358636 0.85918592 0.85830583 0.84686469 0.85610561\n",
            " 0.83520352 0.85654565 0.83608361 0.78305831 0.759956   0.75313531\n",
            " 0.74367437 0.76611661 0.75555556 0.75753575 0.75885589 0.73575358\n",
            " 0.73377338 0.72057206 0.72167217 0.71991199 0.72145215 0.75181518\n",
            " 0.76259626 0.75621562 0.76281628 0.78393839 0.78415842 0.7819582\n",
            " 0.77887789 0.79647965 0.79713971 0.82442244 0.79163916 0.81210121\n",
            " 0.8019802  0.80506051 0.8330033  0.83608361 0.84224422 0.8239824\n",
            " 0.81562156 0.81826183 0.8369637  0.84642464 0.84532453 0.85588559\n",
            " 0.8750275  0.87062706 0.87634763 0.86644664 0.86776678 0.85830583\n",
            " 0.87942794 0.86512651 0.87238724 0.87194719 0.86050605 0.85940594\n",
            " 0.89680968 0.95489549 1.         0.98921892 0.99317932 0.99713971\n",
            " 0.9909791  0.99185919 0.9960396  0.9190319  0.88074807 0.88118812\n",
            " 0.87260726 0.87062706 0.90869087 0.8990099  0.85984598 0.80836084\n",
            " 0.83960396 0.83318985 0.82914275 0.83094275]\n",
            "3 day output [[0.8332503]]\n",
            "4 day input [0.71287129 0.7320132  0.7489549  0.7630363  0.76039604 0.74433443\n",
            " 0.75841584 0.75841584 0.76369637 0.82486249 0.82970297 0.8259626\n",
            " 0.84224422 0.82684268 0.88030803 0.87590759 0.87194719 0.8730473\n",
            " 0.86358636 0.85918592 0.85830583 0.84686469 0.85610561 0.83520352\n",
            " 0.85654565 0.83608361 0.78305831 0.759956   0.75313531 0.74367437\n",
            " 0.76611661 0.75555556 0.75753575 0.75885589 0.73575358 0.73377338\n",
            " 0.72057206 0.72167217 0.71991199 0.72145215 0.75181518 0.76259626\n",
            " 0.75621562 0.76281628 0.78393839 0.78415842 0.7819582  0.77887789\n",
            " 0.79647965 0.79713971 0.82442244 0.79163916 0.81210121 0.8019802\n",
            " 0.80506051 0.8330033  0.83608361 0.84224422 0.8239824  0.81562156\n",
            " 0.81826183 0.8369637  0.84642464 0.84532453 0.85588559 0.8750275\n",
            " 0.87062706 0.87634763 0.86644664 0.86776678 0.85830583 0.87942794\n",
            " 0.86512651 0.87238724 0.87194719 0.86050605 0.85940594 0.89680968\n",
            " 0.95489549 1.         0.98921892 0.99317932 0.99713971 0.9909791\n",
            " 0.99185919 0.9960396  0.9190319  0.88074807 0.88118812 0.87260726\n",
            " 0.87062706 0.90869087 0.8990099  0.85984598 0.80836084 0.83960396\n",
            " 0.83318985 0.82914275 0.83094275 0.83325028]\n",
            "4 day output [[0.8347145]]\n",
            "5 day input [0.7320132  0.7489549  0.7630363  0.76039604 0.74433443 0.75841584\n",
            " 0.75841584 0.76369637 0.82486249 0.82970297 0.8259626  0.84224422\n",
            " 0.82684268 0.88030803 0.87590759 0.87194719 0.8730473  0.86358636\n",
            " 0.85918592 0.85830583 0.84686469 0.85610561 0.83520352 0.85654565\n",
            " 0.83608361 0.78305831 0.759956   0.75313531 0.74367437 0.76611661\n",
            " 0.75555556 0.75753575 0.75885589 0.73575358 0.73377338 0.72057206\n",
            " 0.72167217 0.71991199 0.72145215 0.75181518 0.76259626 0.75621562\n",
            " 0.76281628 0.78393839 0.78415842 0.7819582  0.77887789 0.79647965\n",
            " 0.79713971 0.82442244 0.79163916 0.81210121 0.8019802  0.80506051\n",
            " 0.8330033  0.83608361 0.84224422 0.8239824  0.81562156 0.81826183\n",
            " 0.8369637  0.84642464 0.84532453 0.85588559 0.8750275  0.87062706\n",
            " 0.87634763 0.86644664 0.86776678 0.85830583 0.87942794 0.86512651\n",
            " 0.87238724 0.87194719 0.86050605 0.85940594 0.89680968 0.95489549\n",
            " 1.         0.98921892 0.99317932 0.99713971 0.9909791  0.99185919\n",
            " 0.9960396  0.9190319  0.88074807 0.88118812 0.87260726 0.87062706\n",
            " 0.90869087 0.8990099  0.85984598 0.80836084 0.83960396 0.83318985\n",
            " 0.82914275 0.83094275 0.83325028 0.83471447]\n",
            "5 day output [[0.83488846]]\n",
            "6 day input [0.7489549  0.7630363  0.76039604 0.74433443 0.75841584 0.75841584\n",
            " 0.76369637 0.82486249 0.82970297 0.8259626  0.84224422 0.82684268\n",
            " 0.88030803 0.87590759 0.87194719 0.8730473  0.86358636 0.85918592\n",
            " 0.85830583 0.84686469 0.85610561 0.83520352 0.85654565 0.83608361\n",
            " 0.78305831 0.759956   0.75313531 0.74367437 0.76611661 0.75555556\n",
            " 0.75753575 0.75885589 0.73575358 0.73377338 0.72057206 0.72167217\n",
            " 0.71991199 0.72145215 0.75181518 0.76259626 0.75621562 0.76281628\n",
            " 0.78393839 0.78415842 0.7819582  0.77887789 0.79647965 0.79713971\n",
            " 0.82442244 0.79163916 0.81210121 0.8019802  0.80506051 0.8330033\n",
            " 0.83608361 0.84224422 0.8239824  0.81562156 0.81826183 0.8369637\n",
            " 0.84642464 0.84532453 0.85588559 0.8750275  0.87062706 0.87634763\n",
            " 0.86644664 0.86776678 0.85830583 0.87942794 0.86512651 0.87238724\n",
            " 0.87194719 0.86050605 0.85940594 0.89680968 0.95489549 1.\n",
            " 0.98921892 0.99317932 0.99713971 0.9909791  0.99185919 0.9960396\n",
            " 0.9190319  0.88074807 0.88118812 0.87260726 0.87062706 0.90869087\n",
            " 0.8990099  0.85984598 0.80836084 0.83960396 0.83318985 0.82914275\n",
            " 0.83094275 0.83325028 0.83471447 0.83488846]\n",
            "6 day output [[0.83346957]]\n",
            "7 day input [0.7630363  0.76039604 0.74433443 0.75841584 0.75841584 0.76369637\n",
            " 0.82486249 0.82970297 0.8259626  0.84224422 0.82684268 0.88030803\n",
            " 0.87590759 0.87194719 0.8730473  0.86358636 0.85918592 0.85830583\n",
            " 0.84686469 0.85610561 0.83520352 0.85654565 0.83608361 0.78305831\n",
            " 0.759956   0.75313531 0.74367437 0.76611661 0.75555556 0.75753575\n",
            " 0.75885589 0.73575358 0.73377338 0.72057206 0.72167217 0.71991199\n",
            " 0.72145215 0.75181518 0.76259626 0.75621562 0.76281628 0.78393839\n",
            " 0.78415842 0.7819582  0.77887789 0.79647965 0.79713971 0.82442244\n",
            " 0.79163916 0.81210121 0.8019802  0.80506051 0.8330033  0.83608361\n",
            " 0.84224422 0.8239824  0.81562156 0.81826183 0.8369637  0.84642464\n",
            " 0.84532453 0.85588559 0.8750275  0.87062706 0.87634763 0.86644664\n",
            " 0.86776678 0.85830583 0.87942794 0.86512651 0.87238724 0.87194719\n",
            " 0.86050605 0.85940594 0.89680968 0.95489549 1.         0.98921892\n",
            " 0.99317932 0.99713971 0.9909791  0.99185919 0.9960396  0.9190319\n",
            " 0.88074807 0.88118812 0.87260726 0.87062706 0.90869087 0.8990099\n",
            " 0.85984598 0.80836084 0.83960396 0.83318985 0.82914275 0.83094275\n",
            " 0.83325028 0.83471447 0.83488846 0.83346957]\n",
            "7 day output [[0.8303192]]\n",
            "8 day input [0.76039604 0.74433443 0.75841584 0.75841584 0.76369637 0.82486249\n",
            " 0.82970297 0.8259626  0.84224422 0.82684268 0.88030803 0.87590759\n",
            " 0.87194719 0.8730473  0.86358636 0.85918592 0.85830583 0.84686469\n",
            " 0.85610561 0.83520352 0.85654565 0.83608361 0.78305831 0.759956\n",
            " 0.75313531 0.74367437 0.76611661 0.75555556 0.75753575 0.75885589\n",
            " 0.73575358 0.73377338 0.72057206 0.72167217 0.71991199 0.72145215\n",
            " 0.75181518 0.76259626 0.75621562 0.76281628 0.78393839 0.78415842\n",
            " 0.7819582  0.77887789 0.79647965 0.79713971 0.82442244 0.79163916\n",
            " 0.81210121 0.8019802  0.80506051 0.8330033  0.83608361 0.84224422\n",
            " 0.8239824  0.81562156 0.81826183 0.8369637  0.84642464 0.84532453\n",
            " 0.85588559 0.8750275  0.87062706 0.87634763 0.86644664 0.86776678\n",
            " 0.85830583 0.87942794 0.86512651 0.87238724 0.87194719 0.86050605\n",
            " 0.85940594 0.89680968 0.95489549 1.         0.98921892 0.99317932\n",
            " 0.99713971 0.9909791  0.99185919 0.9960396  0.9190319  0.88074807\n",
            " 0.88118812 0.87260726 0.87062706 0.90869087 0.8990099  0.85984598\n",
            " 0.80836084 0.83960396 0.83318985 0.82914275 0.83094275 0.83325028\n",
            " 0.83471447 0.83488846 0.83346957 0.83031923]\n",
            "8 day output [[0.8255147]]\n",
            "9 day input [0.74433443 0.75841584 0.75841584 0.76369637 0.82486249 0.82970297\n",
            " 0.8259626  0.84224422 0.82684268 0.88030803 0.87590759 0.87194719\n",
            " 0.8730473  0.86358636 0.85918592 0.85830583 0.84686469 0.85610561\n",
            " 0.83520352 0.85654565 0.83608361 0.78305831 0.759956   0.75313531\n",
            " 0.74367437 0.76611661 0.75555556 0.75753575 0.75885589 0.73575358\n",
            " 0.73377338 0.72057206 0.72167217 0.71991199 0.72145215 0.75181518\n",
            " 0.76259626 0.75621562 0.76281628 0.78393839 0.78415842 0.7819582\n",
            " 0.77887789 0.79647965 0.79713971 0.82442244 0.79163916 0.81210121\n",
            " 0.8019802  0.80506051 0.8330033  0.83608361 0.84224422 0.8239824\n",
            " 0.81562156 0.81826183 0.8369637  0.84642464 0.84532453 0.85588559\n",
            " 0.8750275  0.87062706 0.87634763 0.86644664 0.86776678 0.85830583\n",
            " 0.87942794 0.86512651 0.87238724 0.87194719 0.86050605 0.85940594\n",
            " 0.89680968 0.95489549 1.         0.98921892 0.99317932 0.99713971\n",
            " 0.9909791  0.99185919 0.9960396  0.9190319  0.88074807 0.88118812\n",
            " 0.87260726 0.87062706 0.90869087 0.8990099  0.85984598 0.80836084\n",
            " 0.83960396 0.83318985 0.82914275 0.83094275 0.83325028 0.83471447\n",
            " 0.83488846 0.83346957 0.83031923 0.82551467]\n",
            "9 day output [[0.81932086]]\n",
            "10 day input [0.75841584 0.75841584 0.76369637 0.82486249 0.82970297 0.8259626\n",
            " 0.84224422 0.82684268 0.88030803 0.87590759 0.87194719 0.8730473\n",
            " 0.86358636 0.85918592 0.85830583 0.84686469 0.85610561 0.83520352\n",
            " 0.85654565 0.83608361 0.78305831 0.759956   0.75313531 0.74367437\n",
            " 0.76611661 0.75555556 0.75753575 0.75885589 0.73575358 0.73377338\n",
            " 0.72057206 0.72167217 0.71991199 0.72145215 0.75181518 0.76259626\n",
            " 0.75621562 0.76281628 0.78393839 0.78415842 0.7819582  0.77887789\n",
            " 0.79647965 0.79713971 0.82442244 0.79163916 0.81210121 0.8019802\n",
            " 0.80506051 0.8330033  0.83608361 0.84224422 0.8239824  0.81562156\n",
            " 0.81826183 0.8369637  0.84642464 0.84532453 0.85588559 0.8750275\n",
            " 0.87062706 0.87634763 0.86644664 0.86776678 0.85830583 0.87942794\n",
            " 0.86512651 0.87238724 0.87194719 0.86050605 0.85940594 0.89680968\n",
            " 0.95489549 1.         0.98921892 0.99317932 0.99713971 0.9909791\n",
            " 0.99185919 0.9960396  0.9190319  0.88074807 0.88118812 0.87260726\n",
            " 0.87062706 0.90869087 0.8990099  0.85984598 0.80836084 0.83960396\n",
            " 0.83318985 0.82914275 0.83094275 0.83325028 0.83471447 0.83488846\n",
            " 0.83346957 0.83031923 0.82551467 0.81932086]\n",
            "10 day output [[0.81212515]]\n",
            "11 day input [0.75841584 0.76369637 0.82486249 0.82970297 0.8259626  0.84224422\n",
            " 0.82684268 0.88030803 0.87590759 0.87194719 0.8730473  0.86358636\n",
            " 0.85918592 0.85830583 0.84686469 0.85610561 0.83520352 0.85654565\n",
            " 0.83608361 0.78305831 0.759956   0.75313531 0.74367437 0.76611661\n",
            " 0.75555556 0.75753575 0.75885589 0.73575358 0.73377338 0.72057206\n",
            " 0.72167217 0.71991199 0.72145215 0.75181518 0.76259626 0.75621562\n",
            " 0.76281628 0.78393839 0.78415842 0.7819582  0.77887789 0.79647965\n",
            " 0.79713971 0.82442244 0.79163916 0.81210121 0.8019802  0.80506051\n",
            " 0.8330033  0.83608361 0.84224422 0.8239824  0.81562156 0.81826183\n",
            " 0.8369637  0.84642464 0.84532453 0.85588559 0.8750275  0.87062706\n",
            " 0.87634763 0.86644664 0.86776678 0.85830583 0.87942794 0.86512651\n",
            " 0.87238724 0.87194719 0.86050605 0.85940594 0.89680968 0.95489549\n",
            " 1.         0.98921892 0.99317932 0.99713971 0.9909791  0.99185919\n",
            " 0.9960396  0.9190319  0.88074807 0.88118812 0.87260726 0.87062706\n",
            " 0.90869087 0.8990099  0.85984598 0.80836084 0.83960396 0.83318985\n",
            " 0.82914275 0.83094275 0.83325028 0.83471447 0.83488846 0.83346957\n",
            " 0.83031923 0.82551467 0.81932086 0.81212515]\n",
            "11 day output [[0.80436414]]\n",
            "12 day input [0.76369637 0.82486249 0.82970297 0.8259626  0.84224422 0.82684268\n",
            " 0.88030803 0.87590759 0.87194719 0.8730473  0.86358636 0.85918592\n",
            " 0.85830583 0.84686469 0.85610561 0.83520352 0.85654565 0.83608361\n",
            " 0.78305831 0.759956   0.75313531 0.74367437 0.76611661 0.75555556\n",
            " 0.75753575 0.75885589 0.73575358 0.73377338 0.72057206 0.72167217\n",
            " 0.71991199 0.72145215 0.75181518 0.76259626 0.75621562 0.76281628\n",
            " 0.78393839 0.78415842 0.7819582  0.77887789 0.79647965 0.79713971\n",
            " 0.82442244 0.79163916 0.81210121 0.8019802  0.80506051 0.8330033\n",
            " 0.83608361 0.84224422 0.8239824  0.81562156 0.81826183 0.8369637\n",
            " 0.84642464 0.84532453 0.85588559 0.8750275  0.87062706 0.87634763\n",
            " 0.86644664 0.86776678 0.85830583 0.87942794 0.86512651 0.87238724\n",
            " 0.87194719 0.86050605 0.85940594 0.89680968 0.95489549 1.\n",
            " 0.98921892 0.99317932 0.99713971 0.9909791  0.99185919 0.9960396\n",
            " 0.9190319  0.88074807 0.88118812 0.87260726 0.87062706 0.90869087\n",
            " 0.8990099  0.85984598 0.80836084 0.83960396 0.83318985 0.82914275\n",
            " 0.83094275 0.83325028 0.83471447 0.83488846 0.83346957 0.83031923\n",
            " 0.82551467 0.81932086 0.81212515 0.80436414]\n",
            "12 day output [[0.7964598]]\n",
            "13 day input [0.82486249 0.82970297 0.8259626  0.84224422 0.82684268 0.88030803\n",
            " 0.87590759 0.87194719 0.8730473  0.86358636 0.85918592 0.85830583\n",
            " 0.84686469 0.85610561 0.83520352 0.85654565 0.83608361 0.78305831\n",
            " 0.759956   0.75313531 0.74367437 0.76611661 0.75555556 0.75753575\n",
            " 0.75885589 0.73575358 0.73377338 0.72057206 0.72167217 0.71991199\n",
            " 0.72145215 0.75181518 0.76259626 0.75621562 0.76281628 0.78393839\n",
            " 0.78415842 0.7819582  0.77887789 0.79647965 0.79713971 0.82442244\n",
            " 0.79163916 0.81210121 0.8019802  0.80506051 0.8330033  0.83608361\n",
            " 0.84224422 0.8239824  0.81562156 0.81826183 0.8369637  0.84642464\n",
            " 0.84532453 0.85588559 0.8750275  0.87062706 0.87634763 0.86644664\n",
            " 0.86776678 0.85830583 0.87942794 0.86512651 0.87238724 0.87194719\n",
            " 0.86050605 0.85940594 0.89680968 0.95489549 1.         0.98921892\n",
            " 0.99317932 0.99713971 0.9909791  0.99185919 0.9960396  0.9190319\n",
            " 0.88074807 0.88118812 0.87260726 0.87062706 0.90869087 0.8990099\n",
            " 0.85984598 0.80836084 0.83960396 0.83318985 0.82914275 0.83094275\n",
            " 0.83325028 0.83471447 0.83488846 0.83346957 0.83031923 0.82551467\n",
            " 0.81932086 0.81212515 0.80436414 0.79645979]\n",
            "13 day output [[0.7887695]]\n",
            "14 day input [0.82970297 0.8259626  0.84224422 0.82684268 0.88030803 0.87590759\n",
            " 0.87194719 0.8730473  0.86358636 0.85918592 0.85830583 0.84686469\n",
            " 0.85610561 0.83520352 0.85654565 0.83608361 0.78305831 0.759956\n",
            " 0.75313531 0.74367437 0.76611661 0.75555556 0.75753575 0.75885589\n",
            " 0.73575358 0.73377338 0.72057206 0.72167217 0.71991199 0.72145215\n",
            " 0.75181518 0.76259626 0.75621562 0.76281628 0.78393839 0.78415842\n",
            " 0.7819582  0.77887789 0.79647965 0.79713971 0.82442244 0.79163916\n",
            " 0.81210121 0.8019802  0.80506051 0.8330033  0.83608361 0.84224422\n",
            " 0.8239824  0.81562156 0.81826183 0.8369637  0.84642464 0.84532453\n",
            " 0.85588559 0.8750275  0.87062706 0.87634763 0.86644664 0.86776678\n",
            " 0.85830583 0.87942794 0.86512651 0.87238724 0.87194719 0.86050605\n",
            " 0.85940594 0.89680968 0.95489549 1.         0.98921892 0.99317932\n",
            " 0.99713971 0.9909791  0.99185919 0.9960396  0.9190319  0.88074807\n",
            " 0.88118812 0.87260726 0.87062706 0.90869087 0.8990099  0.85984598\n",
            " 0.80836084 0.83960396 0.83318985 0.82914275 0.83094275 0.83325028\n",
            " 0.83471447 0.83488846 0.83346957 0.83031923 0.82551467 0.81932086\n",
            " 0.81212515 0.80436414 0.79645979 0.78876948]\n",
            "14 day output [[0.78155595]]\n",
            "15 day input [0.8259626  0.84224422 0.82684268 0.88030803 0.87590759 0.87194719\n",
            " 0.8730473  0.86358636 0.85918592 0.85830583 0.84686469 0.85610561\n",
            " 0.83520352 0.85654565 0.83608361 0.78305831 0.759956   0.75313531\n",
            " 0.74367437 0.76611661 0.75555556 0.75753575 0.75885589 0.73575358\n",
            " 0.73377338 0.72057206 0.72167217 0.71991199 0.72145215 0.75181518\n",
            " 0.76259626 0.75621562 0.76281628 0.78393839 0.78415842 0.7819582\n",
            " 0.77887789 0.79647965 0.79713971 0.82442244 0.79163916 0.81210121\n",
            " 0.8019802  0.80506051 0.8330033  0.83608361 0.84224422 0.8239824\n",
            " 0.81562156 0.81826183 0.8369637  0.84642464 0.84532453 0.85588559\n",
            " 0.8750275  0.87062706 0.87634763 0.86644664 0.86776678 0.85830583\n",
            " 0.87942794 0.86512651 0.87238724 0.87194719 0.86050605 0.85940594\n",
            " 0.89680968 0.95489549 1.         0.98921892 0.99317932 0.99713971\n",
            " 0.9909791  0.99185919 0.9960396  0.9190319  0.88074807 0.88118812\n",
            " 0.87260726 0.87062706 0.90869087 0.8990099  0.85984598 0.80836084\n",
            " 0.83960396 0.83318985 0.82914275 0.83094275 0.83325028 0.83471447\n",
            " 0.83488846 0.83346957 0.83031923 0.82551467 0.81932086 0.81212515\n",
            " 0.80436414 0.79645979 0.78876948 0.78155595]\n",
            "15 day output [[0.774972]]\n",
            "16 day input [0.84224422 0.82684268 0.88030803 0.87590759 0.87194719 0.8730473\n",
            " 0.86358636 0.85918592 0.85830583 0.84686469 0.85610561 0.83520352\n",
            " 0.85654565 0.83608361 0.78305831 0.759956   0.75313531 0.74367437\n",
            " 0.76611661 0.75555556 0.75753575 0.75885589 0.73575358 0.73377338\n",
            " 0.72057206 0.72167217 0.71991199 0.72145215 0.75181518 0.76259626\n",
            " 0.75621562 0.76281628 0.78393839 0.78415842 0.7819582  0.77887789\n",
            " 0.79647965 0.79713971 0.82442244 0.79163916 0.81210121 0.8019802\n",
            " 0.80506051 0.8330033  0.83608361 0.84224422 0.8239824  0.81562156\n",
            " 0.81826183 0.8369637  0.84642464 0.84532453 0.85588559 0.8750275\n",
            " 0.87062706 0.87634763 0.86644664 0.86776678 0.85830583 0.87942794\n",
            " 0.86512651 0.87238724 0.87194719 0.86050605 0.85940594 0.89680968\n",
            " 0.95489549 1.         0.98921892 0.99317932 0.99713971 0.9909791\n",
            " 0.99185919 0.9960396  0.9190319  0.88074807 0.88118812 0.87260726\n",
            " 0.87062706 0.90869087 0.8990099  0.85984598 0.80836084 0.83960396\n",
            " 0.83318985 0.82914275 0.83094275 0.83325028 0.83471447 0.83488846\n",
            " 0.83346957 0.83031923 0.82551467 0.81932086 0.81212515 0.80436414\n",
            " 0.79645979 0.78876948 0.78155595 0.77497202]\n",
            "16 day output [[0.76906455]]\n",
            "17 day input [0.82684268 0.88030803 0.87590759 0.87194719 0.8730473  0.86358636\n",
            " 0.85918592 0.85830583 0.84686469 0.85610561 0.83520352 0.85654565\n",
            " 0.83608361 0.78305831 0.759956   0.75313531 0.74367437 0.76611661\n",
            " 0.75555556 0.75753575 0.75885589 0.73575358 0.73377338 0.72057206\n",
            " 0.72167217 0.71991199 0.72145215 0.75181518 0.76259626 0.75621562\n",
            " 0.76281628 0.78393839 0.78415842 0.7819582  0.77887789 0.79647965\n",
            " 0.79713971 0.82442244 0.79163916 0.81210121 0.8019802  0.80506051\n",
            " 0.8330033  0.83608361 0.84224422 0.8239824  0.81562156 0.81826183\n",
            " 0.8369637  0.84642464 0.84532453 0.85588559 0.8750275  0.87062706\n",
            " 0.87634763 0.86644664 0.86776678 0.85830583 0.87942794 0.86512651\n",
            " 0.87238724 0.87194719 0.86050605 0.85940594 0.89680968 0.95489549\n",
            " 1.         0.98921892 0.99317932 0.99713971 0.9909791  0.99185919\n",
            " 0.9960396  0.9190319  0.88074807 0.88118812 0.87260726 0.87062706\n",
            " 0.90869087 0.8990099  0.85984598 0.80836084 0.83960396 0.83318985\n",
            " 0.82914275 0.83094275 0.83325028 0.83471447 0.83488846 0.83346957\n",
            " 0.83031923 0.82551467 0.81932086 0.81212515 0.80436414 0.79645979\n",
            " 0.78876948 0.78155595 0.77497202 0.76906455]\n",
            "17 day output [[0.76379013]]\n",
            "18 day input [0.88030803 0.87590759 0.87194719 0.8730473  0.86358636 0.85918592\n",
            " 0.85830583 0.84686469 0.85610561 0.83520352 0.85654565 0.83608361\n",
            " 0.78305831 0.759956   0.75313531 0.74367437 0.76611661 0.75555556\n",
            " 0.75753575 0.75885589 0.73575358 0.73377338 0.72057206 0.72167217\n",
            " 0.71991199 0.72145215 0.75181518 0.76259626 0.75621562 0.76281628\n",
            " 0.78393839 0.78415842 0.7819582  0.77887789 0.79647965 0.79713971\n",
            " 0.82442244 0.79163916 0.81210121 0.8019802  0.80506051 0.8330033\n",
            " 0.83608361 0.84224422 0.8239824  0.81562156 0.81826183 0.8369637\n",
            " 0.84642464 0.84532453 0.85588559 0.8750275  0.87062706 0.87634763\n",
            " 0.86644664 0.86776678 0.85830583 0.87942794 0.86512651 0.87238724\n",
            " 0.87194719 0.86050605 0.85940594 0.89680968 0.95489549 1.\n",
            " 0.98921892 0.99317932 0.99713971 0.9909791  0.99185919 0.9960396\n",
            " 0.9190319  0.88074807 0.88118812 0.87260726 0.87062706 0.90869087\n",
            " 0.8990099  0.85984598 0.80836084 0.83960396 0.83318985 0.82914275\n",
            " 0.83094275 0.83325028 0.83471447 0.83488846 0.83346957 0.83031923\n",
            " 0.82551467 0.81932086 0.81212515 0.80436414 0.79645979 0.78876948\n",
            " 0.78155595 0.77497202 0.76906455 0.76379013]\n",
            "18 day output [[0.7590358]]\n",
            "19 day input [0.87590759 0.87194719 0.8730473  0.86358636 0.85918592 0.85830583\n",
            " 0.84686469 0.85610561 0.83520352 0.85654565 0.83608361 0.78305831\n",
            " 0.759956   0.75313531 0.74367437 0.76611661 0.75555556 0.75753575\n",
            " 0.75885589 0.73575358 0.73377338 0.72057206 0.72167217 0.71991199\n",
            " 0.72145215 0.75181518 0.76259626 0.75621562 0.76281628 0.78393839\n",
            " 0.78415842 0.7819582  0.77887789 0.79647965 0.79713971 0.82442244\n",
            " 0.79163916 0.81210121 0.8019802  0.80506051 0.8330033  0.83608361\n",
            " 0.84224422 0.8239824  0.81562156 0.81826183 0.8369637  0.84642464\n",
            " 0.84532453 0.85588559 0.8750275  0.87062706 0.87634763 0.86644664\n",
            " 0.86776678 0.85830583 0.87942794 0.86512651 0.87238724 0.87194719\n",
            " 0.86050605 0.85940594 0.89680968 0.95489549 1.         0.98921892\n",
            " 0.99317932 0.99713971 0.9909791  0.99185919 0.9960396  0.9190319\n",
            " 0.88074807 0.88118812 0.87260726 0.87062706 0.90869087 0.8990099\n",
            " 0.85984598 0.80836084 0.83960396 0.83318985 0.82914275 0.83094275\n",
            " 0.83325028 0.83471447 0.83488846 0.83346957 0.83031923 0.82551467\n",
            " 0.81932086 0.81212515 0.80436414 0.79645979 0.78876948 0.78155595\n",
            " 0.77497202 0.76906455 0.76379013 0.75903583]\n",
            "19 day output [[0.7546482]]\n",
            "20 day input [0.87194719 0.8730473  0.86358636 0.85918592 0.85830583 0.84686469\n",
            " 0.85610561 0.83520352 0.85654565 0.83608361 0.78305831 0.759956\n",
            " 0.75313531 0.74367437 0.76611661 0.75555556 0.75753575 0.75885589\n",
            " 0.73575358 0.73377338 0.72057206 0.72167217 0.71991199 0.72145215\n",
            " 0.75181518 0.76259626 0.75621562 0.76281628 0.78393839 0.78415842\n",
            " 0.7819582  0.77887789 0.79647965 0.79713971 0.82442244 0.79163916\n",
            " 0.81210121 0.8019802  0.80506051 0.8330033  0.83608361 0.84224422\n",
            " 0.8239824  0.81562156 0.81826183 0.8369637  0.84642464 0.84532453\n",
            " 0.85588559 0.8750275  0.87062706 0.87634763 0.86644664 0.86776678\n",
            " 0.85830583 0.87942794 0.86512651 0.87238724 0.87194719 0.86050605\n",
            " 0.85940594 0.89680968 0.95489549 1.         0.98921892 0.99317932\n",
            " 0.99713971 0.9909791  0.99185919 0.9960396  0.9190319  0.88074807\n",
            " 0.88118812 0.87260726 0.87062706 0.90869087 0.8990099  0.85984598\n",
            " 0.80836084 0.83960396 0.83318985 0.82914275 0.83094275 0.83325028\n",
            " 0.83471447 0.83488846 0.83346957 0.83031923 0.82551467 0.81932086\n",
            " 0.81212515 0.80436414 0.79645979 0.78876948 0.78155595 0.77497202\n",
            " 0.76906455 0.76379013 0.75903583 0.75464821]\n",
            "20 day output [[0.7504573]]\n",
            "21 day input [0.8730473  0.86358636 0.85918592 0.85830583 0.84686469 0.85610561\n",
            " 0.83520352 0.85654565 0.83608361 0.78305831 0.759956   0.75313531\n",
            " 0.74367437 0.76611661 0.75555556 0.75753575 0.75885589 0.73575358\n",
            " 0.73377338 0.72057206 0.72167217 0.71991199 0.72145215 0.75181518\n",
            " 0.76259626 0.75621562 0.76281628 0.78393839 0.78415842 0.7819582\n",
            " 0.77887789 0.79647965 0.79713971 0.82442244 0.79163916 0.81210121\n",
            " 0.8019802  0.80506051 0.8330033  0.83608361 0.84224422 0.8239824\n",
            " 0.81562156 0.81826183 0.8369637  0.84642464 0.84532453 0.85588559\n",
            " 0.8750275  0.87062706 0.87634763 0.86644664 0.86776678 0.85830583\n",
            " 0.87942794 0.86512651 0.87238724 0.87194719 0.86050605 0.85940594\n",
            " 0.89680968 0.95489549 1.         0.98921892 0.99317932 0.99713971\n",
            " 0.9909791  0.99185919 0.9960396  0.9190319  0.88074807 0.88118812\n",
            " 0.87260726 0.87062706 0.90869087 0.8990099  0.85984598 0.80836084\n",
            " 0.83960396 0.83318985 0.82914275 0.83094275 0.83325028 0.83471447\n",
            " 0.83488846 0.83346957 0.83031923 0.82551467 0.81932086 0.81212515\n",
            " 0.80436414 0.79645979 0.78876948 0.78155595 0.77497202 0.76906455\n",
            " 0.76379013 0.75903583 0.75464821 0.75045729]\n",
            "21 day output [[0.746301]]\n",
            "22 day input [0.86358636 0.85918592 0.85830583 0.84686469 0.85610561 0.83520352\n",
            " 0.85654565 0.83608361 0.78305831 0.759956   0.75313531 0.74367437\n",
            " 0.76611661 0.75555556 0.75753575 0.75885589 0.73575358 0.73377338\n",
            " 0.72057206 0.72167217 0.71991199 0.72145215 0.75181518 0.76259626\n",
            " 0.75621562 0.76281628 0.78393839 0.78415842 0.7819582  0.77887789\n",
            " 0.79647965 0.79713971 0.82442244 0.79163916 0.81210121 0.8019802\n",
            " 0.80506051 0.8330033  0.83608361 0.84224422 0.8239824  0.81562156\n",
            " 0.81826183 0.8369637  0.84642464 0.84532453 0.85588559 0.8750275\n",
            " 0.87062706 0.87634763 0.86644664 0.86776678 0.85830583 0.87942794\n",
            " 0.86512651 0.87238724 0.87194719 0.86050605 0.85940594 0.89680968\n",
            " 0.95489549 1.         0.98921892 0.99317932 0.99713971 0.9909791\n",
            " 0.99185919 0.9960396  0.9190319  0.88074807 0.88118812 0.87260726\n",
            " 0.87062706 0.90869087 0.8990099  0.85984598 0.80836084 0.83960396\n",
            " 0.83318985 0.82914275 0.83094275 0.83325028 0.83471447 0.83488846\n",
            " 0.83346957 0.83031923 0.82551467 0.81932086 0.81212515 0.80436414\n",
            " 0.79645979 0.78876948 0.78155595 0.77497202 0.76906455 0.76379013\n",
            " 0.75903583 0.75464821 0.75045729 0.746301  ]\n",
            "22 day output [[0.7420406]]\n",
            "23 day input [0.85918592 0.85830583 0.84686469 0.85610561 0.83520352 0.85654565\n",
            " 0.83608361 0.78305831 0.759956   0.75313531 0.74367437 0.76611661\n",
            " 0.75555556 0.75753575 0.75885589 0.73575358 0.73377338 0.72057206\n",
            " 0.72167217 0.71991199 0.72145215 0.75181518 0.76259626 0.75621562\n",
            " 0.76281628 0.78393839 0.78415842 0.7819582  0.77887789 0.79647965\n",
            " 0.79713971 0.82442244 0.79163916 0.81210121 0.8019802  0.80506051\n",
            " 0.8330033  0.83608361 0.84224422 0.8239824  0.81562156 0.81826183\n",
            " 0.8369637  0.84642464 0.84532453 0.85588559 0.8750275  0.87062706\n",
            " 0.87634763 0.86644664 0.86776678 0.85830583 0.87942794 0.86512651\n",
            " 0.87238724 0.87194719 0.86050605 0.85940594 0.89680968 0.95489549\n",
            " 1.         0.98921892 0.99317932 0.99713971 0.9909791  0.99185919\n",
            " 0.9960396  0.9190319  0.88074807 0.88118812 0.87260726 0.87062706\n",
            " 0.90869087 0.8990099  0.85984598 0.80836084 0.83960396 0.83318985\n",
            " 0.82914275 0.83094275 0.83325028 0.83471447 0.83488846 0.83346957\n",
            " 0.83031923 0.82551467 0.81932086 0.81212515 0.80436414 0.79645979\n",
            " 0.78876948 0.78155595 0.77497202 0.76906455 0.76379013 0.75903583\n",
            " 0.75464821 0.75045729 0.746301   0.74204057]\n",
            "23 day output [[0.73757523]]\n",
            "24 day input [0.85830583 0.84686469 0.85610561 0.83520352 0.85654565 0.83608361\n",
            " 0.78305831 0.759956   0.75313531 0.74367437 0.76611661 0.75555556\n",
            " 0.75753575 0.75885589 0.73575358 0.73377338 0.72057206 0.72167217\n",
            " 0.71991199 0.72145215 0.75181518 0.76259626 0.75621562 0.76281628\n",
            " 0.78393839 0.78415842 0.7819582  0.77887789 0.79647965 0.79713971\n",
            " 0.82442244 0.79163916 0.81210121 0.8019802  0.80506051 0.8330033\n",
            " 0.83608361 0.84224422 0.8239824  0.81562156 0.81826183 0.8369637\n",
            " 0.84642464 0.84532453 0.85588559 0.8750275  0.87062706 0.87634763\n",
            " 0.86644664 0.86776678 0.85830583 0.87942794 0.86512651 0.87238724\n",
            " 0.87194719 0.86050605 0.85940594 0.89680968 0.95489549 1.\n",
            " 0.98921892 0.99317932 0.99713971 0.9909791  0.99185919 0.9960396\n",
            " 0.9190319  0.88074807 0.88118812 0.87260726 0.87062706 0.90869087\n",
            " 0.8990099  0.85984598 0.80836084 0.83960396 0.83318985 0.82914275\n",
            " 0.83094275 0.83325028 0.83471447 0.83488846 0.83346957 0.83031923\n",
            " 0.82551467 0.81932086 0.81212515 0.80436414 0.79645979 0.78876948\n",
            " 0.78155595 0.77497202 0.76906455 0.76379013 0.75903583 0.75464821\n",
            " 0.75045729 0.746301   0.74204057 0.73757523]\n",
            "24 day output [[0.73284435]]\n",
            "25 day input [0.84686469 0.85610561 0.83520352 0.85654565 0.83608361 0.78305831\n",
            " 0.759956   0.75313531 0.74367437 0.76611661 0.75555556 0.75753575\n",
            " 0.75885589 0.73575358 0.73377338 0.72057206 0.72167217 0.71991199\n",
            " 0.72145215 0.75181518 0.76259626 0.75621562 0.76281628 0.78393839\n",
            " 0.78415842 0.7819582  0.77887789 0.79647965 0.79713971 0.82442244\n",
            " 0.79163916 0.81210121 0.8019802  0.80506051 0.8330033  0.83608361\n",
            " 0.84224422 0.8239824  0.81562156 0.81826183 0.8369637  0.84642464\n",
            " 0.84532453 0.85588559 0.8750275  0.87062706 0.87634763 0.86644664\n",
            " 0.86776678 0.85830583 0.87942794 0.86512651 0.87238724 0.87194719\n",
            " 0.86050605 0.85940594 0.89680968 0.95489549 1.         0.98921892\n",
            " 0.99317932 0.99713971 0.9909791  0.99185919 0.9960396  0.9190319\n",
            " 0.88074807 0.88118812 0.87260726 0.87062706 0.90869087 0.8990099\n",
            " 0.85984598 0.80836084 0.83960396 0.83318985 0.82914275 0.83094275\n",
            " 0.83325028 0.83471447 0.83488846 0.83346957 0.83031923 0.82551467\n",
            " 0.81932086 0.81212515 0.80436414 0.79645979 0.78876948 0.78155595\n",
            " 0.77497202 0.76906455 0.76379013 0.75903583 0.75464821 0.75045729\n",
            " 0.746301   0.74204057 0.73757523 0.73284435]\n",
            "25 day output [[0.72782934]]\n",
            "26 day input [0.85610561 0.83520352 0.85654565 0.83608361 0.78305831 0.759956\n",
            " 0.75313531 0.74367437 0.76611661 0.75555556 0.75753575 0.75885589\n",
            " 0.73575358 0.73377338 0.72057206 0.72167217 0.71991199 0.72145215\n",
            " 0.75181518 0.76259626 0.75621562 0.76281628 0.78393839 0.78415842\n",
            " 0.7819582  0.77887789 0.79647965 0.79713971 0.82442244 0.79163916\n",
            " 0.81210121 0.8019802  0.80506051 0.8330033  0.83608361 0.84224422\n",
            " 0.8239824  0.81562156 0.81826183 0.8369637  0.84642464 0.84532453\n",
            " 0.85588559 0.8750275  0.87062706 0.87634763 0.86644664 0.86776678\n",
            " 0.85830583 0.87942794 0.86512651 0.87238724 0.87194719 0.86050605\n",
            " 0.85940594 0.89680968 0.95489549 1.         0.98921892 0.99317932\n",
            " 0.99713971 0.9909791  0.99185919 0.9960396  0.9190319  0.88074807\n",
            " 0.88118812 0.87260726 0.87062706 0.90869087 0.8990099  0.85984598\n",
            " 0.80836084 0.83960396 0.83318985 0.82914275 0.83094275 0.83325028\n",
            " 0.83471447 0.83488846 0.83346957 0.83031923 0.82551467 0.81932086\n",
            " 0.81212515 0.80436414 0.79645979 0.78876948 0.78155595 0.77497202\n",
            " 0.76906455 0.76379013 0.75903583 0.75464821 0.75045729 0.746301\n",
            " 0.74204057 0.73757523 0.73284435 0.72782934]\n",
            "26 day output [[0.7225474]]\n",
            "27 day input [0.83520352 0.85654565 0.83608361 0.78305831 0.759956   0.75313531\n",
            " 0.74367437 0.76611661 0.75555556 0.75753575 0.75885589 0.73575358\n",
            " 0.73377338 0.72057206 0.72167217 0.71991199 0.72145215 0.75181518\n",
            " 0.76259626 0.75621562 0.76281628 0.78393839 0.78415842 0.7819582\n",
            " 0.77887789 0.79647965 0.79713971 0.82442244 0.79163916 0.81210121\n",
            " 0.8019802  0.80506051 0.8330033  0.83608361 0.84224422 0.8239824\n",
            " 0.81562156 0.81826183 0.8369637  0.84642464 0.84532453 0.85588559\n",
            " 0.8750275  0.87062706 0.87634763 0.86644664 0.86776678 0.85830583\n",
            " 0.87942794 0.86512651 0.87238724 0.87194719 0.86050605 0.85940594\n",
            " 0.89680968 0.95489549 1.         0.98921892 0.99317932 0.99713971\n",
            " 0.9909791  0.99185919 0.9960396  0.9190319  0.88074807 0.88118812\n",
            " 0.87260726 0.87062706 0.90869087 0.8990099  0.85984598 0.80836084\n",
            " 0.83960396 0.83318985 0.82914275 0.83094275 0.83325028 0.83471447\n",
            " 0.83488846 0.83346957 0.83031923 0.82551467 0.81932086 0.81212515\n",
            " 0.80436414 0.79645979 0.78876948 0.78155595 0.77497202 0.76906455\n",
            " 0.76379013 0.75903583 0.75464821 0.75045729 0.746301   0.74204057\n",
            " 0.73757523 0.73284435 0.72782934 0.72254741]\n",
            "27 day output [[0.71704316]]\n",
            "28 day input [0.85654565 0.83608361 0.78305831 0.759956   0.75313531 0.74367437\n",
            " 0.76611661 0.75555556 0.75753575 0.75885589 0.73575358 0.73377338\n",
            " 0.72057206 0.72167217 0.71991199 0.72145215 0.75181518 0.76259626\n",
            " 0.75621562 0.76281628 0.78393839 0.78415842 0.7819582  0.77887789\n",
            " 0.79647965 0.79713971 0.82442244 0.79163916 0.81210121 0.8019802\n",
            " 0.80506051 0.8330033  0.83608361 0.84224422 0.8239824  0.81562156\n",
            " 0.81826183 0.8369637  0.84642464 0.84532453 0.85588559 0.8750275\n",
            " 0.87062706 0.87634763 0.86644664 0.86776678 0.85830583 0.87942794\n",
            " 0.86512651 0.87238724 0.87194719 0.86050605 0.85940594 0.89680968\n",
            " 0.95489549 1.         0.98921892 0.99317932 0.99713971 0.9909791\n",
            " 0.99185919 0.9960396  0.9190319  0.88074807 0.88118812 0.87260726\n",
            " 0.87062706 0.90869087 0.8990099  0.85984598 0.80836084 0.83960396\n",
            " 0.83318985 0.82914275 0.83094275 0.83325028 0.83471447 0.83488846\n",
            " 0.83346957 0.83031923 0.82551467 0.81932086 0.81212515 0.80436414\n",
            " 0.79645979 0.78876948 0.78155595 0.77497202 0.76906455 0.76379013\n",
            " 0.75903583 0.75464821 0.75045729 0.746301   0.74204057 0.73757523\n",
            " 0.73284435 0.72782934 0.72254741 0.71704316]\n",
            "28 day output [[0.71137965]]\n",
            "29 day input [0.83608361 0.78305831 0.759956   0.75313531 0.74367437 0.76611661\n",
            " 0.75555556 0.75753575 0.75885589 0.73575358 0.73377338 0.72057206\n",
            " 0.72167217 0.71991199 0.72145215 0.75181518 0.76259626 0.75621562\n",
            " 0.76281628 0.78393839 0.78415842 0.7819582  0.77887789 0.79647965\n",
            " 0.79713971 0.82442244 0.79163916 0.81210121 0.8019802  0.80506051\n",
            " 0.8330033  0.83608361 0.84224422 0.8239824  0.81562156 0.81826183\n",
            " 0.8369637  0.84642464 0.84532453 0.85588559 0.8750275  0.87062706\n",
            " 0.87634763 0.86644664 0.86776678 0.85830583 0.87942794 0.86512651\n",
            " 0.87238724 0.87194719 0.86050605 0.85940594 0.89680968 0.95489549\n",
            " 1.         0.98921892 0.99317932 0.99713971 0.9909791  0.99185919\n",
            " 0.9960396  0.9190319  0.88074807 0.88118812 0.87260726 0.87062706\n",
            " 0.90869087 0.8990099  0.85984598 0.80836084 0.83960396 0.83318985\n",
            " 0.82914275 0.83094275 0.83325028 0.83471447 0.83488846 0.83346957\n",
            " 0.83031923 0.82551467 0.81932086 0.81212515 0.80436414 0.79645979\n",
            " 0.78876948 0.78155595 0.77497202 0.76906455 0.76379013 0.75903583\n",
            " 0.75464821 0.75045729 0.746301   0.74204057 0.73757523 0.73284435\n",
            " 0.72782934 0.72254741 0.71704316 0.71137965]\n",
            "29 day output [[0.70562685]]\n",
            "[[0.833189845085144], [0.8291427493095398], [0.8309427499771118], [0.8332502841949463], [0.8347144722938538], [0.8348884582519531], [0.833469569683075], [0.8303192257881165], [0.8255146741867065], [0.8193208575248718], [0.8121251463890076], [0.8043641448020935], [0.7964597940444946], [0.7887694835662842], [0.7815559506416321], [0.7749720215797424], [0.7690645456314087], [0.7637901306152344], [0.7590358257293701], [0.7546482086181641], [0.7504572868347168], [0.746300995349884], [0.7420405745506287], [0.7375752329826355], [0.732844352722168], [0.7278293371200562], [0.7225474119186401], [0.7170431613922119], [0.7113796472549438], [0.7056268453598022]]\n"
          ]
        }
      ],
      "source": [
        "# demonstrate prediction for next 10 days\n",
        "from numpy import array\n",
        "\n",
        "lst_output=[]\n",
        "n_steps=100\n",
        "i=0\n",
        "while(i<30):\n",
        "    \n",
        "    if(len(temp_input)>100):\n",
        "        #print(temp_input)\n",
        "        x_input=np.array(temp_input[1:])\n",
        "        print(\"{} day input {}\".format(i,x_input))\n",
        "        x_input=x_input.reshape(1,-1)\n",
        "        x_input = x_input.reshape((1, n_steps, 1))\n",
        "        #print(x_input)\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(\"{} day output {}\".format(i,yhat))\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        temp_input=temp_input[1:]\n",
        "        #print(temp_input)\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    else:\n",
        "        x_input = x_input.reshape((1, n_steps,1))\n",
        "        yhat = model.predict(x_input, verbose=0)\n",
        "        print(yhat[0])\n",
        "        temp_input.extend(yhat[0].tolist())\n",
        "        print(len(temp_input))\n",
        "        lst_output.extend(yhat.tolist())\n",
        "        i=i+1\n",
        "    \n",
        "\n",
        "print(lst_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ld0bXpoQuvKk"
      },
      "outputs": [],
      "source": [
        "day_new=np.arange(1,101)\n",
        "day_pred=np.arange(101,131)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXpoaL-MuvKl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFmHuRUtuvKl",
        "outputId": "5fb9f4a1-860c-4b60-a20e-71ab8ef47577"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1258"
            ]
          },
          "execution_count": 391,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-arw8c9ZuvKl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "3ZKSUBFRuvKm",
        "outputId": "4513124a-c603-42ff-dcc1-8b15f67e9249"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4cb045b650>]"
            ]
          },
          "metadata": {},
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(day_new,scaler.inverse_transform(df1[1158:]))\n",
        "plt.plot(day_pred,scaler.inverse_transform(lst_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "I-pzJ3hkuvKm",
        "outputId": "37c54cac-f233-4336-df93-fcee0140f357"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4cb03c2b90>]"
            ]
          },
          "metadata": {},
          "execution_count": 105
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "df3=df1.tolist()\n",
        "df3.extend(lst_output)\n",
        "plt.plot(df3[1200:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3TNNfnEuvKm"
      },
      "outputs": [],
      "source": [
        "df3=scaler.inverse_transform(df3).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "7fcOq7rruvKn",
        "outputId": "e7066544-4a24-4e57-d85c-1ff8fb5b0356"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4cb053d990>]"
            ]
          },
          "metadata": {},
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(df3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrOD4eFFuvKn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "model=DecisionTreeClassifier()\n",
        "kfold_validation=KFold(10)"
      ],
      "metadata": {
        "id": "sOSbkErYu8CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_score\n",
        "results=cross_val_score(model,ytest,test_predict,cv=kfold_validation)\n",
        "print(results)\n",
        "print(np.mean(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzYmmB0pvIJF",
        "outputId": "869d2929-838a-44d3-9d9b-3963adf5db42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nan nan nan nan nan nan nan nan nan nan]\n",
            "nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "10 fits failed out of a total of 10.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.69152915 0.7218922  0.73135316 0.72739273 0.72739273 0.7331133\n",
            " 0.74367434 0.73663366 0.7452145  0.73531353 0.720132   0.7278328\n",
            " 0.71947193 0.73509353 0.7839384  0.77073705 0.80572057 0.76061606\n",
            " 0.7661166  0.7678768  0.7762376  0.7614961  0.7823982  0.79647964\n",
            " 0.8019802  0.7848185  0.78019804 0.7830583  0.76237625 0.7531353\n",
            " 0.7408141  0.7322332  0.7410341  0.7232123  0.73025304 0.74939495\n",
            " 0.78019804 0.78371835 0.7718372  0.7619362  0.7421342  0.7617162\n",
            " 0.7533553  0.769637   0.74631464 0.75951594 0.76765674 0.80462044\n",
            " 0.74653465 0.70143014 0.6871287  0.6827283  0.68184817 0.6860286\n",
            " 0.710231   0.70737076 0.7049505  0.7322332  0.73553354 0.7566557\n",
            " 0.73817384 0.75951594 0.7469747  0.7456546  0.74345434 0.7326733\n",
            " 0.7278328  0.73179317 0.7326733  0.73355335 0.74961495 0.71947193\n",
            " 0.74367434 0.71045107 0.70011    0.70121014 0.6668867  0.6794279\n",
            " 0.6457646  0.620242   0.639604   0.64048404 0.63146317 0.6310231\n",
            " 0.6028603  0.60132015 0.6246425  0.6316832  0.6319032  0.6508251\n",
            " 0.63674366 0.64950496 0.6442244  0.6475248  0.6134213  0.62244225\n",
            " 0.63146317 0.63344336 0.64466447 0.680088   0.68074805 0.66732675\n",
            " 0.68668866 0.67744774 0.69042903 0.7084708  0.7069307  0.73531353\n",
            " 0.7390539  0.7344335  0.6811881  0.65126514 0.6393839  0.67876786\n",
            " 0.679868   0.679648   0.6928493  0.7023102  0.74939495 0.75423545\n",
            " 0.7375138  0.7218922  0.7405941  0.74631464 0.7018702  0.6959296\n",
            " 0.7084708  0.73025304 0.740154   0.7425743  0.770077   0.7859186\n",
            " 0.76875687 0.77865785 0.7927393  0.8030803  0.8079208  0.8079208\n",
            " 0.8325633  0.8451045  0.819582   0.8022002  0.80154014 0.80022\n",
            " 0.7940594  0.7870187  0.8061606  0.77029705 0.7790979  0.7909791\n",
            " 0.78349835 0.78679866 0.78063804 0.7971397  0.8052805  0.82068205\n",
            " 0.82222223 0.84136415 0.8587459  0.88030803 0.8721672  0.8490649\n",
            " 0.8972497  0.89746976 0.9064906  0.8987899  0.8829483  0.8710671\n",
            " 0.8651265  0.85566556 0.8418042  0.8270627  0.8358636  0.81364137\n",
            " 0.8244224  0.82332236 0.8369637  0.82354236 0.8257426  0.8312431\n",
            " 0.82640266 0.81364137 0.8004401  0.78173816 0.77733773 0.7874587\n",
            " 0.7810781  0.77865785 0.7262926  0.71573156 0.71925193 0.71265125\n",
            " 0.6809681  0.65786576 0.70913094 0.70253026 0.6939494  0.68866885\n",
            " 0.6979098  0.71045107 0.679868   0.68844885 0.6781078  0.6728273\n",
            " 0.72255224 0.7320132  0.74763477 0.729813   0.72563255 0.71045107\n",
            " 0.689989   0.7128713  0.7320132  0.7489549  0.7630363  0.76039606\n",
            " 0.74433446 0.7584158  0.7584158  0.7636964  0.8248625  0.829703\n",
            " 0.8259626  0.8422442  0.82684267 0.88030803 0.8759076  0.87194717\n",
            " 0.8730473  0.86358637 0.85918593 0.8583058  0.8468647  0.8561056\n",
            " 0.8352035  0.8565456  0.8360836  0.7830583  0.759956   0.7531353\n",
            " 0.74367434 0.7661166  0.75555557 0.75753576 0.7588559  0.7357536\n",
            " 0.73377335 0.72057205 0.7216722  0.719912   0.7214521  0.7518152\n",
            " 0.76259625 0.75621563 0.7628163  0.7839384  0.7841584  0.7819582\n",
            " 0.7788779  0.79647964 0.7971397  0.8244224  0.79163915 0.8121012\n",
            " 0.8019802  0.8050605  0.8330033  0.8360836  0.8422442  0.8239824\n",
            " 0.81562155 0.8182618  0.8369637  0.84642464 0.8453245  0.85588557\n",
            " 0.8750275  0.87062705 0.87634766 0.8664467  0.8677668  0.8583058\n",
            " 0.87942797 0.8651265  0.87238723 0.87194717 0.86050606 0.85940593\n",
            " 0.8968097  0.9548955  1.         0.98921895 0.9931793  0.9971397\n",
            " 0.9909791  0.9918592  0.9960396  0.9190319  0.8807481  0.8811881\n",
            " 0.87260723 0.87062705 0.90869087 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.73025304 0.74939495\n",
            " 0.78019804 0.78371835 0.7718372  0.7619362  0.7421342  0.7617162\n",
            " 0.7533553  0.769637   0.74631464 0.75951594 0.76765674 0.80462044\n",
            " 0.74653465 0.70143014 0.6871287  0.6827283  0.68184817 0.6860286\n",
            " 0.710231   0.70737076 0.7049505  0.7322332  0.73553354 0.7566557\n",
            " 0.73817384 0.75951594 0.7469747  0.7456546  0.74345434 0.7326733\n",
            " 0.7278328  0.73179317 0.7326733  0.73355335 0.74961495 0.71947193\n",
            " 0.74367434 0.71045107 0.70011    0.70121014 0.6668867  0.6794279\n",
            " 0.6457646  0.620242   0.639604   0.64048404 0.63146317 0.6310231\n",
            " 0.6028603  0.60132015 0.6246425  0.6316832  0.6319032  0.6508251\n",
            " 0.63674366 0.64950496 0.6442244  0.6475248  0.6134213  0.62244225\n",
            " 0.63146317 0.63344336 0.64466447 0.680088   0.68074805 0.66732675\n",
            " 0.68668866 0.67744774 0.69042903 0.7084708  0.7069307  0.73531353\n",
            " 0.7390539  0.7344335  0.6811881  0.65126514 0.6393839  0.67876786\n",
            " 0.679868   0.679648   0.6928493  0.7023102  0.74939495 0.75423545\n",
            " 0.7375138  0.7218922  0.7405941  0.74631464 0.7018702  0.6959296\n",
            " 0.7084708  0.73025304 0.740154   0.7425743  0.770077   0.7859186\n",
            " 0.76875687 0.77865785 0.7927393  0.8030803  0.8079208  0.8079208\n",
            " 0.8325633  0.8451045  0.819582   0.8022002  0.80154014 0.80022\n",
            " 0.7940594  0.7870187  0.8061606  0.77029705 0.7790979  0.7909791\n",
            " 0.78349835 0.78679866 0.78063804 0.7971397  0.8052805  0.82068205\n",
            " 0.82222223 0.84136415 0.8587459  0.88030803 0.8721672  0.8490649\n",
            " 0.8972497  0.89746976 0.9064906  0.8987899  0.8829483  0.8710671\n",
            " 0.8651265  0.85566556 0.8418042  0.8270627  0.8358636  0.81364137\n",
            " 0.8244224  0.82332236 0.8369637  0.82354236 0.8257426  0.8312431\n",
            " 0.82640266 0.81364137 0.8004401  0.78173816 0.77733773 0.7874587\n",
            " 0.7810781  0.77865785 0.7262926  0.71573156 0.71925193 0.71265125\n",
            " 0.6809681  0.65786576 0.70913094 0.70253026 0.6939494  0.68866885\n",
            " 0.6979098  0.71045107 0.679868   0.68844885 0.6781078  0.6728273\n",
            " 0.72255224 0.7320132  0.74763477 0.729813   0.72563255 0.71045107\n",
            " 0.689989   0.7128713  0.7320132  0.7489549  0.7630363  0.76039606\n",
            " 0.74433446 0.7584158  0.7584158  0.7636964  0.8248625  0.829703\n",
            " 0.8259626  0.8422442  0.82684267 0.88030803 0.8759076  0.87194717\n",
            " 0.8730473  0.86358637 0.85918593 0.8583058  0.8468647  0.8561056\n",
            " 0.8352035  0.8565456  0.8360836  0.7830583  0.759956   0.7531353\n",
            " 0.74367434 0.7661166  0.75555557 0.75753576 0.7588559  0.7357536\n",
            " 0.73377335 0.72057205 0.7216722  0.719912   0.7214521  0.7518152\n",
            " 0.76259625 0.75621563 0.7628163  0.7839384  0.7841584  0.7819582\n",
            " 0.7788779  0.79647964 0.7971397  0.8244224  0.79163915 0.8121012\n",
            " 0.8019802  0.8050605  0.8330033  0.8360836  0.8422442  0.8239824\n",
            " 0.81562155 0.8182618  0.8369637  0.84642464 0.8453245  0.85588557\n",
            " 0.8750275  0.87062705 0.87634766 0.8664467  0.8677668  0.8583058\n",
            " 0.87942797 0.8651265  0.87238723 0.87194717 0.86050606 0.85940593\n",
            " 0.8968097  0.9548955  1.         0.98921895 0.9931793  0.9971397\n",
            " 0.9909791  0.9918592  0.9960396  0.9190319  0.8807481  0.8811881\n",
            " 0.87260723 0.87062705 0.90869087 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.7326733  0.73355335 0.74961495 0.71947193\n",
            " 0.74367434 0.71045107 0.70011    0.70121014 0.6668867  0.6794279\n",
            " 0.6457646  0.620242   0.639604   0.64048404 0.63146317 0.6310231\n",
            " 0.6028603  0.60132015 0.6246425  0.6316832  0.6319032  0.6508251\n",
            " 0.63674366 0.64950496 0.6442244  0.6475248  0.6134213  0.62244225\n",
            " 0.63146317 0.63344336 0.64466447 0.680088   0.68074805 0.66732675\n",
            " 0.68668866 0.67744774 0.69042903 0.7084708  0.7069307  0.73531353\n",
            " 0.7390539  0.7344335  0.6811881  0.65126514 0.6393839  0.67876786\n",
            " 0.679868   0.679648   0.6928493  0.7023102  0.74939495 0.75423545\n",
            " 0.7375138  0.7218922  0.7405941  0.74631464 0.7018702  0.6959296\n",
            " 0.7084708  0.73025304 0.740154   0.7425743  0.770077   0.7859186\n",
            " 0.76875687 0.77865785 0.7927393  0.8030803  0.8079208  0.8079208\n",
            " 0.8325633  0.8451045  0.819582   0.8022002  0.80154014 0.80022\n",
            " 0.7940594  0.7870187  0.8061606  0.77029705 0.7790979  0.7909791\n",
            " 0.78349835 0.78679866 0.78063804 0.7971397  0.8052805  0.82068205\n",
            " 0.82222223 0.84136415 0.8587459  0.88030803 0.8721672  0.8490649\n",
            " 0.8972497  0.89746976 0.9064906  0.8987899  0.8829483  0.8710671\n",
            " 0.8651265  0.85566556 0.8418042  0.8270627  0.8358636  0.81364137\n",
            " 0.8244224  0.82332236 0.8369637  0.82354236 0.8257426  0.8312431\n",
            " 0.82640266 0.81364137 0.8004401  0.78173816 0.77733773 0.7874587\n",
            " 0.7810781  0.77865785 0.7262926  0.71573156 0.71925193 0.71265125\n",
            " 0.6809681  0.65786576 0.70913094 0.70253026 0.6939494  0.68866885\n",
            " 0.6979098  0.71045107 0.679868   0.68844885 0.6781078  0.6728273\n",
            " 0.72255224 0.7320132  0.74763477 0.729813   0.72563255 0.71045107\n",
            " 0.689989   0.7128713  0.7320132  0.7489549  0.7630363  0.76039606\n",
            " 0.74433446 0.7584158  0.7584158  0.7636964  0.8248625  0.829703\n",
            " 0.8259626  0.8422442  0.82684267 0.88030803 0.8759076  0.87194717\n",
            " 0.8730473  0.86358637 0.85918593 0.8583058  0.8468647  0.8561056\n",
            " 0.8352035  0.8565456  0.8360836  0.7830583  0.759956   0.7531353\n",
            " 0.74367434 0.7661166  0.75555557 0.75753576 0.7588559  0.7357536\n",
            " 0.73377335 0.72057205 0.7216722  0.719912   0.7214521  0.7518152\n",
            " 0.76259625 0.75621563 0.7628163  0.7839384  0.7841584  0.7819582\n",
            " 0.7788779  0.79647964 0.7971397  0.8244224  0.79163915 0.8121012\n",
            " 0.8019802  0.8050605  0.8330033  0.8360836  0.8422442  0.8239824\n",
            " 0.81562155 0.8182618  0.8369637  0.84642464 0.8453245  0.85588557\n",
            " 0.8750275  0.87062705 0.87634766 0.8664467  0.8677668  0.8583058\n",
            " 0.87942797 0.8651265  0.87238723 0.87194717 0.86050606 0.85940593\n",
            " 0.8968097  0.9548955  1.         0.98921895 0.9931793  0.9971397\n",
            " 0.9909791  0.9918592  0.9960396  0.9190319  0.8807481  0.8811881\n",
            " 0.87260723 0.87062705 0.90869087 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.68668866 0.67744774 0.69042903 0.7084708  0.7069307  0.73531353\n",
            " 0.7390539  0.7344335  0.6811881  0.65126514 0.6393839  0.67876786\n",
            " 0.679868   0.679648   0.6928493  0.7023102  0.74939495 0.75423545\n",
            " 0.7375138  0.7218922  0.7405941  0.74631464 0.7018702  0.6959296\n",
            " 0.7084708  0.73025304 0.740154   0.7425743  0.770077   0.7859186\n",
            " 0.76875687 0.77865785 0.7927393  0.8030803  0.8079208  0.8079208\n",
            " 0.8325633  0.8451045  0.819582   0.8022002  0.80154014 0.80022\n",
            " 0.7940594  0.7870187  0.8061606  0.77029705 0.7790979  0.7909791\n",
            " 0.78349835 0.78679866 0.78063804 0.7971397  0.8052805  0.82068205\n",
            " 0.82222223 0.84136415 0.8587459  0.88030803 0.8721672  0.8490649\n",
            " 0.8972497  0.89746976 0.9064906  0.8987899  0.8829483  0.8710671\n",
            " 0.8651265  0.85566556 0.8418042  0.8270627  0.8358636  0.81364137\n",
            " 0.8244224  0.82332236 0.8369637  0.82354236 0.8257426  0.8312431\n",
            " 0.82640266 0.81364137 0.8004401  0.78173816 0.77733773 0.7874587\n",
            " 0.7810781  0.77865785 0.7262926  0.71573156 0.71925193 0.71265125\n",
            " 0.6809681  0.65786576 0.70913094 0.70253026 0.6939494  0.68866885\n",
            " 0.6979098  0.71045107 0.679868   0.68844885 0.6781078  0.6728273\n",
            " 0.72255224 0.7320132  0.74763477 0.729813   0.72563255 0.71045107\n",
            " 0.689989   0.7128713  0.7320132  0.7489549  0.7630363  0.76039606\n",
            " 0.74433446 0.7584158  0.7584158  0.7636964  0.8248625  0.829703\n",
            " 0.8259626  0.8422442  0.82684267 0.88030803 0.8759076  0.87194717\n",
            " 0.8730473  0.86358637 0.85918593 0.8583058  0.8468647  0.8561056\n",
            " 0.8352035  0.8565456  0.8360836  0.7830583  0.759956   0.7531353\n",
            " 0.74367434 0.7661166  0.75555557 0.75753576 0.7588559  0.7357536\n",
            " 0.73377335 0.72057205 0.7216722  0.719912   0.7214521  0.7518152\n",
            " 0.76259625 0.75621563 0.7628163  0.7839384  0.7841584  0.7819582\n",
            " 0.7788779  0.79647964 0.7971397  0.8244224  0.79163915 0.8121012\n",
            " 0.8019802  0.8050605  0.8330033  0.8360836  0.8422442  0.8239824\n",
            " 0.81562155 0.8182618  0.8369637  0.84642464 0.8453245  0.85588557\n",
            " 0.8750275  0.87062705 0.87634766 0.8664467  0.8677668  0.8583058\n",
            " 0.87942797 0.8651265  0.87238723 0.87194717 0.86050606 0.85940593\n",
            " 0.8968097  0.9548955  1.         0.98921895 0.9931793  0.9971397\n",
            " 0.9909791  0.9918592  0.9960396  0.9190319  0.8807481  0.8811881\n",
            " 0.87260723 0.87062705 0.90869087 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.8079208  0.8079208\n",
            " 0.8325633  0.8451045  0.819582   0.8022002  0.80154014 0.80022\n",
            " 0.7940594  0.7870187  0.8061606  0.77029705 0.7790979  0.7909791\n",
            " 0.78349835 0.78679866 0.78063804 0.7971397  0.8052805  0.82068205\n",
            " 0.82222223 0.84136415 0.8587459  0.88030803 0.8721672  0.8490649\n",
            " 0.8972497  0.89746976 0.9064906  0.8987899  0.8829483  0.8710671\n",
            " 0.8651265  0.85566556 0.8418042  0.8270627  0.8358636  0.81364137\n",
            " 0.8244224  0.82332236 0.8369637  0.82354236 0.8257426  0.8312431\n",
            " 0.82640266 0.81364137 0.8004401  0.78173816 0.77733773 0.7874587\n",
            " 0.7810781  0.77865785 0.7262926  0.71573156 0.71925193 0.71265125\n",
            " 0.6809681  0.65786576 0.70913094 0.70253026 0.6939494  0.68866885\n",
            " 0.6979098  0.71045107 0.679868   0.68844885 0.6781078  0.6728273\n",
            " 0.72255224 0.7320132  0.74763477 0.729813   0.72563255 0.71045107\n",
            " 0.689989   0.7128713  0.7320132  0.7489549  0.7630363  0.76039606\n",
            " 0.74433446 0.7584158  0.7584158  0.7636964  0.8248625  0.829703\n",
            " 0.8259626  0.8422442  0.82684267 0.88030803 0.8759076  0.87194717\n",
            " 0.8730473  0.86358637 0.85918593 0.8583058  0.8468647  0.8561056\n",
            " 0.8352035  0.8565456  0.8360836  0.7830583  0.759956   0.7531353\n",
            " 0.74367434 0.7661166  0.75555557 0.75753576 0.7588559  0.7357536\n",
            " 0.73377335 0.72057205 0.7216722  0.719912   0.7214521  0.7518152\n",
            " 0.76259625 0.75621563 0.7628163  0.7839384  0.7841584  0.7819582\n",
            " 0.7788779  0.79647964 0.7971397  0.8244224  0.79163915 0.8121012\n",
            " 0.8019802  0.8050605  0.8330033  0.8360836  0.8422442  0.8239824\n",
            " 0.81562155 0.8182618  0.8369637  0.84642464 0.8453245  0.85588557\n",
            " 0.8750275  0.87062705 0.87634766 0.8664467  0.8677668  0.8583058\n",
            " 0.87942797 0.8651265  0.87238723 0.87194717 0.86050606 0.85940593\n",
            " 0.8968097  0.9548955  1.         0.98921895 0.9931793  0.9971397\n",
            " 0.9909791  0.9918592  0.9960396  0.9190319  0.8807481  0.8811881\n",
            " 0.87260723 0.87062705 0.90869087 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8418042  0.8270627  0.8358636  0.81364137\n",
            " 0.8244224  0.82332236 0.8369637  0.82354236 0.8257426  0.8312431\n",
            " 0.82640266 0.81364137 0.8004401  0.78173816 0.77733773 0.7874587\n",
            " 0.7810781  0.77865785 0.7262926  0.71573156 0.71925193 0.71265125\n",
            " 0.6809681  0.65786576 0.70913094 0.70253026 0.6939494  0.68866885\n",
            " 0.6979098  0.71045107 0.679868   0.68844885 0.6781078  0.6728273\n",
            " 0.72255224 0.7320132  0.74763477 0.729813   0.72563255 0.71045107\n",
            " 0.689989   0.7128713  0.7320132  0.7489549  0.7630363  0.76039606\n",
            " 0.74433446 0.7584158  0.7584158  0.7636964  0.8248625  0.829703\n",
            " 0.8259626  0.8422442  0.82684267 0.88030803 0.8759076  0.87194717\n",
            " 0.8730473  0.86358637 0.85918593 0.8583058  0.8468647  0.8561056\n",
            " 0.8352035  0.8565456  0.8360836  0.7830583  0.759956   0.7531353\n",
            " 0.74367434 0.7661166  0.75555557 0.75753576 0.7588559  0.7357536\n",
            " 0.73377335 0.72057205 0.7216722  0.719912   0.7214521  0.7518152\n",
            " 0.76259625 0.75621563 0.7628163  0.7839384  0.7841584  0.7819582\n",
            " 0.7788779  0.79647964 0.7971397  0.8244224  0.79163915 0.8121012\n",
            " 0.8019802  0.8050605  0.8330033  0.8360836  0.8422442  0.8239824\n",
            " 0.81562155 0.8182618  0.8369637  0.84642464 0.8453245  0.85588557\n",
            " 0.8750275  0.87062705 0.87634766 0.8664467  0.8677668  0.8583058\n",
            " 0.87942797 0.8651265  0.87238723 0.87194717 0.86050606 0.85940593\n",
            " 0.8968097  0.9548955  1.         0.98921895 0.9931793  0.9971397\n",
            " 0.9909791  0.9918592  0.9960396  0.9190319  0.8807481  0.8811881\n",
            " 0.87260723 0.87062705 0.90869087 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.72255224 0.7320132  0.74763477 0.729813   0.72563255 0.71045107\n",
            " 0.689989   0.7128713  0.7320132  0.7489549  0.7630363  0.76039606\n",
            " 0.74433446 0.7584158  0.7584158  0.7636964  0.8248625  0.829703\n",
            " 0.8259626  0.8422442  0.82684267 0.88030803 0.8759076  0.87194717\n",
            " 0.8730473  0.86358637 0.85918593 0.8583058  0.8468647  0.8561056\n",
            " 0.8352035  0.8565456  0.8360836  0.7830583  0.759956   0.7531353\n",
            " 0.74367434 0.7661166  0.75555557 0.75753576 0.7588559  0.7357536\n",
            " 0.73377335 0.72057205 0.7216722  0.719912   0.7214521  0.7518152\n",
            " 0.76259625 0.75621563 0.7628163  0.7839384  0.7841584  0.7819582\n",
            " 0.7788779  0.79647964 0.7971397  0.8244224  0.79163915 0.8121012\n",
            " 0.8019802  0.8050605  0.8330033  0.8360836  0.8422442  0.8239824\n",
            " 0.81562155 0.8182618  0.8369637  0.84642464 0.8453245  0.85588557\n",
            " 0.8750275  0.87062705 0.87634766 0.8664467  0.8677668  0.8583058\n",
            " 0.87942797 0.8651265  0.87238723 0.87194717 0.86050606 0.85940593\n",
            " 0.8968097  0.9548955  1.         0.98921895 0.9931793  0.9971397\n",
            " 0.9909791  0.9918592  0.9960396  0.9190319  0.8807481  0.8811881\n",
            " 0.87260723 0.87062705 0.90869087 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.759956   0.7531353\n",
            " 0.74367434 0.7661166  0.75555557 0.75753576 0.7588559  0.7357536\n",
            " 0.73377335 0.72057205 0.7216722  0.719912   0.7214521  0.7518152\n",
            " 0.76259625 0.75621563 0.7628163  0.7839384  0.7841584  0.7819582\n",
            " 0.7788779  0.79647964 0.7971397  0.8244224  0.79163915 0.8121012\n",
            " 0.8019802  0.8050605  0.8330033  0.8360836  0.8422442  0.8239824\n",
            " 0.81562155 0.8182618  0.8369637  0.84642464 0.8453245  0.85588557\n",
            " 0.8750275  0.87062705 0.87634766 0.8664467  0.8677668  0.8583058\n",
            " 0.87942797 0.8651265  0.87238723 0.87194717 0.86050606 0.85940593\n",
            " 0.8968097  0.9548955  1.         0.98921895 0.9931793  0.9971397\n",
            " 0.9909791  0.9918592  0.9960396  0.9190319  0.8807481  0.8811881\n",
            " 0.87260723 0.87062705 0.90869087 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.8369637  0.84642464 0.8453245  0.85588557\n",
            " 0.8750275  0.87062705 0.87634766 0.8664467  0.8677668  0.8583058\n",
            " 0.87942797 0.8651265  0.87238723 0.87194717 0.86050606 0.85940593\n",
            " 0.8968097  0.9548955  1.         0.98921895 0.9931793  0.9971397\n",
            " 0.9909791  0.9918592  0.9960396  0.9190319  0.8807481  0.8811881\n",
            " 0.87260723 0.87062705 0.90869087 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import LeaveOneOut\n",
        "model=DecisionTreeClassifier()\n",
        "leave_validation=LeaveOneOut()\n",
        "results=cross_val_score(model,ytest,test_predict,cv=leave_validation)\n",
        "results\n",
        "print(np.mean(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y73D-v_-hue",
        "outputId": "8e556834-5afc-470c-baff-9ba2af315a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "340 fits failed out of a total of 340.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.5190319  0.5430143  0.54147416 0.54675466 0.55335534 0.54367435\n",
            " 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5430143  0.54147416 0.54675466 0.55335534 0.54367435\n",
            " 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.54147416 0.54675466 0.55335534 0.54367435\n",
            " 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54675466 0.55335534 0.54367435\n",
            " 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.55335534 0.54367435\n",
            " 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.54367435\n",
            " 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.5540154  0.5359736  0.5768977  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5359736  0.5768977  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5768977  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5639164  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.56237626\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.5793179  0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.60748076 0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60660064 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.59141916 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.589879   0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.58679867\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.59163916 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.5949395  0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.6068207  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.5892189  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5872387\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.579978   0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.5878988  0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.6264026  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6310231  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.64664465 0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.6442244\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6580858  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6684269  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.69834983 0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69152915 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.7218922  0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.73135316\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.7331133  0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.74367434 0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.73663366 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.7452145\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.73531353 0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.720132   0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.7278328  0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.71947193 0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.73509353 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.7839384\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.77073705 0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.80572057 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.76061606 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.7661166  0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7678768  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7762376\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7614961  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7823982  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.79647964 0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.8019802  0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.7848185  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.78019804\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.76237625 0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.7531353  0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7408141  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7322332  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7410341\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7232123  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.73025304 0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.74939495 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.78019804 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78371835 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.7718372\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7619362  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7421342  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7617162  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7533553  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.769637   0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.74631464\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.76765674 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.80462044 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.74653465 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.70143014 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.6871287\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6827283  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.68184817 0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.6860286  0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.710231   0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.70737076 0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.7049505\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7322332  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.73553354 0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.7566557  0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.73817384 0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.75951594 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.7469747\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7456546  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.74345434 0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.7326733  0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7278328  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.73179317 0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.7326733\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.73355335 0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.74961495 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.71947193 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.74367434 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.71045107 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.70011\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70121014 0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.6668867  0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6794279  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6457646  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.620242   0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.639604\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.64048404 0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.63146317 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.6310231  0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6028603  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.60132015 0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.6246425\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6316832  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6319032  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6508251  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.63674366 0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.64950496 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.6442244\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6475248  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6134213  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.62244225 0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.63146317 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63344336 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.64466447\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.680088   0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.68074805 0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.66732675 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.68668866 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.67744774 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.69042903\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7069307  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.73531353 0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.7390539  0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7344335  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.6811881\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.65126514 0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.6393839  0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.67876786 0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.679868   0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679648   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.6928493\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.7023102  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.74939495 0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.75423545 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.7375138  0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7218922  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7405941\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.74631464 0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.7018702  0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.6959296  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.7084708  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.73025304 0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.740154\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.7425743  0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.770077   0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.7859186  0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.76875687 0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.77865785 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.7927393\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.8030803  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8079208  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8325633  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8451045  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.819582\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.8022002  0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.80154014 0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80022    0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.7940594  0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7870187  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.8061606\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.77029705 0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.7790979  0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7909791  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.78349835 0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78679866 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78063804\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.8052805  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.82068205 0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82222223 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.84136415 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.8587459\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.88030803 0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.8721672  0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8490649  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8972497  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.89746976 0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.9064906\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.8987899  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8829483  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8710671  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8651265  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.85566556 0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.8418042\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8270627  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8358636  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.81364137 0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.8244224  0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.82332236 0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.8369637\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.82354236 0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.8257426  0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8312431  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.82640266 0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.81364137 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.8004401\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.78173816 0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.77733773 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.7874587  0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7810781  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.77865785 0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.7262926\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.71573156 0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71925193 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71265125 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.6809681  0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.65786576 0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.70913094\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.6939494  0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.68866885 0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.6979098  0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.71045107 0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.679868\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.68844885 0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.6781078  0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6728273  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.72255224 0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.7320132  0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.74763477\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.729813   0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.72563255 0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.71045107 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.689989   0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.7128713  0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7320132\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7489549  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7630363  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.76039606 0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.74433446 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.7584158  0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "2 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7636964  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.8248625  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.829703   0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.8259626  0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8422442  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.82684267\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.8759076  0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.87194717 0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.8730473  0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.86358637 0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.85918593\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8468647  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8561056  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8352035  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8565456  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8360836\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.7830583  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.759956   0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.7531353  0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.74367434 0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.7661166  0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.75555557\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.7588559  0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7357536  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.73377335 0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.72057205 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.7216722\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.719912   0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.7214521  0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7518152  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.76259625 0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.75621563 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.7628163\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7839384  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7841584  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7819582  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7788779  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.79647964 0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.7971397\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.8244224  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.79163915 0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.8121012  0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8019802  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8050605  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8330033\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8360836  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8422442  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8239824  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.81562155 0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.8182618  0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8369637\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.84642464 0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.8453245  0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.85588557 0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.8750275  0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.87062705 0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87634766\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8677668  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8583058  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.87942797 0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.8651265  0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.87238723\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.86050606 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.85940593 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.8968097  0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.9548955  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  1.\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 0.98921895 0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.9931793  0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9971397  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9909791  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9918592  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9960396\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9918592\n",
            " 0.9190319  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9918592\n",
            " 0.9960396  0.8807481  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9918592\n",
            " 0.9960396  0.9190319  0.8811881  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9918592\n",
            " 0.9960396  0.9190319  0.8807481  0.87260723 0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9918592\n",
            " 0.9960396  0.9190319  0.8807481  0.8811881  0.87062705 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9918592\n",
            " 0.9960396  0.9190319  0.8807481  0.8811881  0.87260723 0.90869087\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9918592\n",
            " 0.9960396  0.9190319  0.8807481  0.8811881  0.87260723 0.87062705\n",
            " 0.8990099  0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9918592\n",
            " 0.9960396  0.9190319  0.8807481  0.8811881  0.87260723 0.87062705\n",
            " 0.90869087 0.859846   0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9918592\n",
            " 0.9960396  0.9190319  0.8807481  0.8811881  0.87260723 0.87062705\n",
            " 0.90869087 0.8990099  0.8083608 ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 942, in fit\n",
            "    X_idx_sorted=X_idx_sorted,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\", line 166, in fit\n",
            "    X, y, validate_separately=(check_X_params, check_y_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 578, in _validate_data\n",
            "    X = check_array(X, **check_X_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\", line 773, in check_array\n",
            "    \"if it contains a single sample.\".format(array)\n",
            "ValueError: Expected 2D array, got 1D array instead:\n",
            "array=[0.50165015 0.5190319  0.5430143  0.54147416 0.54675466 0.55335534\n",
            " 0.54367435 0.56919694 0.5540154  0.5359736  0.5768977  0.5639164\n",
            " 0.56237626 0.5793179  0.60748076 0.60660064 0.59141916 0.589879\n",
            " 0.58679867 0.57865787 0.59163916 0.5949395  0.6068207  0.5892189\n",
            " 0.5872387  0.579978   0.5878988  0.6264026  0.6310231  0.64664465\n",
            " 0.6442244  0.6580858  0.6684269  0.69834983 0.69152915 0.7218922\n",
            " 0.73135316 0.72739273 0.72739273 0.7331133  0.74367434 0.73663366\n",
            " 0.7452145  0.73531353 0.720132   0.7278328  0.71947193 0.73509353\n",
            " 0.7839384  0.77073705 0.80572057 0.76061606 0.7661166  0.7678768\n",
            " 0.7762376  0.7614961  0.7823982  0.79647964 0.8019802  0.7848185\n",
            " 0.78019804 0.7830583  0.76237625 0.7531353  0.7408141  0.7322332\n",
            " 0.7410341  0.7232123  0.73025304 0.74939495 0.78019804 0.78371835\n",
            " 0.7718372  0.7619362  0.7421342  0.7617162  0.7533553  0.769637\n",
            " 0.74631464 0.75951594 0.76765674 0.80462044 0.74653465 0.70143014\n",
            " 0.6871287  0.6827283  0.68184817 0.6860286  0.710231   0.70737076\n",
            " 0.7049505  0.7322332  0.73553354 0.7566557  0.73817384 0.75951594\n",
            " 0.7469747  0.7456546  0.74345434 0.7326733  0.7278328  0.73179317\n",
            " 0.7326733  0.73355335 0.74961495 0.71947193 0.74367434 0.71045107\n",
            " 0.70011    0.70121014 0.6668867  0.6794279  0.6457646  0.620242\n",
            " 0.639604   0.64048404 0.63146317 0.6310231  0.6028603  0.60132015\n",
            " 0.6246425  0.6316832  0.6319032  0.6508251  0.63674366 0.64950496\n",
            " 0.6442244  0.6475248  0.6134213  0.62244225 0.63146317 0.63344336\n",
            " 0.64466447 0.680088   0.68074805 0.66732675 0.68668866 0.67744774\n",
            " 0.69042903 0.7084708  0.7069307  0.73531353 0.7390539  0.7344335\n",
            " 0.6811881  0.65126514 0.6393839  0.67876786 0.679868   0.679648\n",
            " 0.6928493  0.7023102  0.74939495 0.75423545 0.7375138  0.7218922\n",
            " 0.7405941  0.74631464 0.7018702  0.6959296  0.7084708  0.73025304\n",
            " 0.740154   0.7425743  0.770077   0.7859186  0.76875687 0.77865785\n",
            " 0.7927393  0.8030803  0.8079208  0.8079208  0.8325633  0.8451045\n",
            " 0.819582   0.8022002  0.80154014 0.80022    0.7940594  0.7870187\n",
            " 0.8061606  0.77029705 0.7790979  0.7909791  0.78349835 0.78679866\n",
            " 0.78063804 0.7971397  0.8052805  0.82068205 0.82222223 0.84136415\n",
            " 0.8587459  0.88030803 0.8721672  0.8490649  0.8972497  0.89746976\n",
            " 0.9064906  0.8987899  0.8829483  0.8710671  0.8651265  0.85566556\n",
            " 0.8418042  0.8270627  0.8358636  0.81364137 0.8244224  0.82332236\n",
            " 0.8369637  0.82354236 0.8257426  0.8312431  0.82640266 0.81364137\n",
            " 0.8004401  0.78173816 0.77733773 0.7874587  0.7810781  0.77865785\n",
            " 0.7262926  0.71573156 0.71925193 0.71265125 0.6809681  0.65786576\n",
            " 0.70913094 0.70253026 0.6939494  0.68866885 0.6979098  0.71045107\n",
            " 0.679868   0.68844885 0.6781078  0.6728273  0.72255224 0.7320132\n",
            " 0.74763477 0.729813   0.72563255 0.71045107 0.689989   0.7128713\n",
            " 0.7320132  0.7489549  0.7630363  0.76039606 0.74433446 0.7584158\n",
            " 0.7584158  0.7636964  0.8248625  0.829703   0.8259626  0.8422442\n",
            " 0.82684267 0.88030803 0.8759076  0.87194717 0.8730473  0.86358637\n",
            " 0.85918593 0.8583058  0.8468647  0.8561056  0.8352035  0.8565456\n",
            " 0.8360836  0.7830583  0.759956   0.7531353  0.74367434 0.7661166\n",
            " 0.75555557 0.75753576 0.7588559  0.7357536  0.73377335 0.72057205\n",
            " 0.7216722  0.719912   0.7214521  0.7518152  0.76259625 0.75621563\n",
            " 0.7628163  0.7839384  0.7841584  0.7819582  0.7788779  0.79647964\n",
            " 0.7971397  0.8244224  0.79163915 0.8121012  0.8019802  0.8050605\n",
            " 0.8330033  0.8360836  0.8422442  0.8239824  0.81562155 0.8182618\n",
            " 0.8369637  0.84642464 0.8453245  0.85588557 0.8750275  0.87062705\n",
            " 0.87634766 0.8664467  0.8677668  0.8583058  0.87942797 0.8651265\n",
            " 0.87238723 0.87194717 0.86050606 0.85940593 0.8968097  0.9548955\n",
            " 1.         0.98921895 0.9931793  0.9971397  0.9909791  0.9918592\n",
            " 0.9960396  0.9190319  0.8807481  0.8811881  0.87260723 0.87062705\n",
            " 0.90869087 0.8990099  0.859846  ].\n",
            "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "lstm stock.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}